nem technical reference version february contents preface iii introduction accounts and addresses account state nem addresses converting public key into address intentional address collision cryptography private and public key signing and verification signature encoding and decoding messages transactions transfer transactions importance transfer transactions activating deactivating multisig related transaction types aggregate modification transactions (multisig modification) multisig signature transactions multisig transactions unconfirmed transactions (spam filter) blocks and the block chain block difficulty block score block creation block chain synchronization reputation system for nodes node interactions local trust value aggregating local trust values enhancing the algorithm benefits the reputation system proof-of-importance eligibility for entering the importance calculation the outlink matrix ncdawarerank clustering the transaction graph calculating importance scores resistance manipulation sybil attack loop attack nothing-at-stake problem comparing importance stake time synchronization gathering samples applying filters remove bad data calculation the effective offset coupling and threshold network node protocol node startup node discovery announcement refresh node selection preface you miss the shots you don't take. wayne gretzky nem movement that aims empower individuals creating new economy based the principles decentralization, financial freedom, and equality opportunity. would like thank the contributors and the many people who have inspired us. bloodyrookie gimre jaguar makoto introduction he'd say hello and introduce himself, but most the cats turned deaf ear, pretending they couldn't hear him, stare right through him. haruki murakami em, its most basic form, crypto currency that built block chain technology. the nem block chain improvement existing block chain technologies. integrates concepts from other cryptocurrencies (e.g. bitcoin) and academic research network theory. nem's primary contribution the crypto currency landscape new consensus mechanism called proof importance (poi). unlike proof work (pow), environmentally sustainable and does not require large scale computing resources perpetuity. poi similar proof stake (pos) except that not solely derived from the size account's balance. incorporates other behaviors that are believed positive for the holistic economy. this way, attempts reward active economy participants the expense inactive ones and dampens the rich getting richer effect that inherent pos. nem's vision the foundation vibrant crypto currency ecosystem that emphasizes security and trustless computing. nem was launched with built-in support for multisig transactions and encrypted messages. additionally, the peer-to-peer (pp) nem network implements modified version eigentrust++ identify and minimize the impact malicious nodes. nem evolving and this just the beginning. stay tuned for more things come. page accounts and addresses wind serves him who addresses his voyage certain port. michel montaigne uses elliptic curve cryptography ensure confidentiality, authenticity and non-repudiability all transactions. each account private+public keypair (section cryptography) and associated with mutable state that updated when transactions are accepted the network. accounts are identified nem addresses, which are derived part from one way mutations public keys. account state the state associated with each account includes the following items: account balance number harvested blocks (see subsection block creation) height the first transaction that referenced the account list multisig accounts and list cosignatories (see subsection multisig related transaction types) information about delegated account status (see subsection importance transfer transactions) importance and ncd aware rank (see section proof-of-importance) vested balance (crucial for poi and nem itself) the underlying crypto currency the nem network called xem. each account's xem balance split into two parts: vested and unvested. whenever account receives xem, the new xem are added the account's unvested balance. when account sends xem, xems are taken from both the vested and the unvested balance, retain the vested unvested ratio additionally, every blocks, the unvested balance moved the vested part. course that not always possible page vested part days figure vesting xem all accounts the nemesis block are fully vested. nem addresses nem address base- encoded triplet consisting of: network byte -bit hash the account's public key byte checksum the checksum allows for quick recognition mistyped addresses. possible send xem any valid address even the address has not previously participated any first block the nem block chain http://en.wikipedia.org/wiki/base page transaction. nobody owns the private key the account which the xem sent, the xem most likely lost forever. converting public key into address order convert public key address, the following steps are performed: perform -bit sha the public key perform -bit ripemd hash resulting from step prepend version byte ripemd hash (either perform -bit sha the result, take the first four bytes checksum concatenate output step and the checksum from step encode result using base example: public key debeddefebaafbeebdfbabaae abcebadcfcdbacbfbcfeef abdaaefecdefcfaaeeafebeedaebf compressed public key: ccafbcdafeffcdbbdddbfed sha-: cdcfbaddbbbcebecedabfdbdfccaddbdfcf ripemd: fceaeddccaaacddaf prepend version: fceaeddccaaacddaf sha- above: aeaabfaabbfeaddaedbb -byte checksum: (first bytes the above) binary address: fceaeddccaaacddafae base- encoding: naprilcusctaynnxbcovkqjlnpceergks pretty-print: napril-cusct-aynnx-bcovk-qjl-npceer-gks page public key: compressed-public-key bytes ripemd(sha compressed-public-key bytes network byte: main net test net sha bytes bytes bytes bytes binary address bytes bytes bytes base- encoding nanemo-ablagr-azr-vvzh-dcxw-xqo-obt figure address generation page intentional address collision possible that two different public keys will yield the same address. such address contains xem would possible for attacker withdraw funds from such account. order for the attack succeed, the attacker would need find private+public keypair such that the sha the public key would the same time equal the ripemd- preimage -bit hash mentioned above. since sha offers bits security, it's mathematically improbable for single sha collision found. due similarities between nem addresses and bitcoin addresses, the probability causing nem address collision roughly the same that causing bitcoin address collision. page cryptography understood the importance principle public key cryptography but it's all moved much faster than expected. did not expect mainstay advanced communications technology. whitfield diffie lock chain technology demands the use some cryptographic concepts. nem, like many other crypto currencies, using cryptography based elliptic curve cryptography. the choice the underlying curve important order guarantee security and speed. nem has chosen use the twisted edwards curve: over the finite field defined the prime number together with the digital signature algorithm called ed. was developed bernstein al. and one the safest and fastest digital signature algorithms []. the base point for the corresponding group called the group has elements. every group element can encoded into bit integer which can also interpreted -bit string and can decoded receive again. for details see []. for the hash function mentioned the paper, nem uses the bit sha hash function. private and public key the private key random -bit integer derive the public key from it, the following steps are taken: h(k) ..., are considered valid prevent the problem signature malleability. verify the signature (r, for the given message and public key one checks and then calculates h(r, and verifies that was computed shown then (h(r, )a)b h(r, will hold. encoding and decoding messages nem uses bouncy castle's aes block cipher implementation cbc mode encrypt and decrypt messages. alice has the private key and wants encrypt message for bob who has the public key (with corresponding group element then the shared secret used when setting the cipher calculated follows: computed from according salt random bytes shared secret h(g salt) http://en.wikipedia.org/wiki/block_cipher_mode_of_operation#cbc page where the -bit sha hash function. another random bytes are used data. thus, the encrypted message payload consists the salt the data the encrypted message block decryption works similar manner. bob has know alice's public key (and his own private key and the salt derive the shared secret: computed from according shared secret h(g salt) supplying the shared secret and the data the cipher engine decrypts the encoded message. page transactions transact business with the girl who ran the gas-pump dean merely threw his t-shirt like scarf and was curt and abrupt usual and got back the car and off roared again. jack kerouac ransactions introduce dynamism into cryptocurrency system. they are the only way altering the state account. newly created transaction that has not yet been included block called unconfirmed transaction. unconfirmed transactions are not guaranteed included any block. result, unconfirmed transactions have effect the account state. the account state only updated when transaction included harvested block and thereby confirmed. different types transactions exist. each type has specific purpose, e.g. transfer xem from one account another convert account multisig account. since transactions consume resources the network there fee for each transaction. the fee depends the transaction type and other parameters the transaction. transactions have deadline. transaction not included block before its deadline, the transaction considered expired and gets dropped the network nodes. the following sections describe the different transaction types. transfer transactions transfer transaction used transfer xem from one account another. message most bytes can attached each transfer transaction. the case encrypted message, only bytes can contain custom data because the salt and the data are part the encrypted message. fees for transfer transactions are divided into two parts: xem per xem transferred, capped xem xem per commenced message bytes (messagelength both fee parts are added give the final fee. page importance transfer transactions nem allows account lease its harvesting power another account through importance transfer transaction. this known delegated harvesting. this allows the original account use its importance harvest remote server (such virtual private server (vps)) without needing have its private key openly exposed the server. fact, this feature allows accounts cold storage harvest without putting any funds risk. the fee for importance transfer transaction xem. activating account can enable delegated harvesting sending special importance transfer transaction that specifies the delegated account. after the importance transfer transaction accepted the network, confirmations are needed before delegated harvesting activation complete. during the activation period, only the original account can harvest but the delegated account cannot. after the activation period, only the delegated account can harvest but the original account cannot. deactivating account with delegated harvesting activated can disable delegated harvesting any time sending special importance transfer transaction that specifies the delegated account. after the importance transfer transaction accepted the network, confirmations are needed before delegated harvesting deactivation complete. during the deactivation period, only the delegated account can harvest but the original account cannot. after the deactivation period, only the original account can harvest but the delegated account cannot. multisig related transaction types nem natively supports m-of-n multisignature accounts. nem multisig transactions have been designed with flexibility mind. any other page transaction (as now: importance transfer, transfer, aggregate modification), can wrapped multisig transaction. multisig transaction itself cannot wrapped inside another multisig transaction. aggregate modification transactions (multisig modification) creating multisig account account can converted into multisig account sending special aggregate modification transaction that signed the multisig account. the transaction specifies information about the cosignatories. the number cosignatories limited subsequently, transactions can initiated from the multisig account. modifying multisig account after multisig account has been created, cosignatory can added removed wrapping aggregate modification transaction multisig transaction. single modification transaction can add one more cosignatories but can remove most one. when adding cosignatories, all existing cosignatories must co-sign the transaction. when removing cosignatory, all existing cosignatories except for the one being removed must co-sign the transaction. the fee for aggregate modification transaction flat fee xem, matter what modifications you make. where the term 'modification' refers the addition deletion cosignatory. multisig signature transactions nem uses multisig signature transactions for letting cosignatories sign multisig transaction. the fee for such signature transaction always xem. the fee deduced from the multisig account, not from the cosignatory's account. multisig signature transaction can only included the block chain the corresponding multisig transaction has been included the block chain. orphaned multisig signature transaction will never included the block chain. page multisig transactions mentioned earlier, any transaction can wrapped multisig transaction. send xem from multisig account another account, transfer transaction must wrapped. the multisig wrapper transaction has fee xem. this fee added the usual transfer transaction fee. the following example shows the steps that must taken more detail: assume that multisig account (m) has balance xem and has three cosignatories (a, and xem needs transferred from another account any the three cosignatories can initiate the xem transfer. assuming that initiates the transfer and and cosign, the following steps must happen for the transaction accepted: creates regular, unsigned transfer transaction that has the multisig account the "signer" and the transfer amount xem wraps the unsigned transfer transaction multisig transaction signs the multisig transaction and sends the nem network and are notified the pending multisig transaction creates multisig signature transaction signing the hash the unsigned transfer transaction and sends the network creates multisig signature transaction signing the hash the unsigned transfer transaction and sends the network once all cosignatories implicitly and and explicitly) have signed the unsigned transfer transaction, the transaction accepted the network and xem transferred from and/or not send multisig signature transaction corresponding the multisig transfer transaction before the transaction deadline, the multisig transfer transaction will rejected the network and xem will transferred from unconfirmed transactions (spam filter) when new transaction created and delivered node, the node page puts the transaction into its unconfirmed transaction cache broadcasts the transaction other nodes (if the transaction valid) there also poll mechanism for unconfirmed transactions during each block chain synchronization round. this allows nodes that not have their port open (and therefore cannot receive broadcasts) learn about new unconfirmed transactions. low transaction fees might tempt some bad actor the network flood the network with new transactions order disturb the network. therefore needed limit the number unconfirmed transactions which are handled the nodes. simply limiting the number unconfirmed transactions that node accepts bad because normal actors still should able send transaction even when someone spamming the network. limiting the number unconfirmed transactions per account also not option since the attacker can create many accounts (s)he wants. nem does filtering smarter way. custom spam filter decides whether new unconfirmed transaction should processed rejected. works the following way: consider the unconfirmed transaction cache having slots long less than slots are filled, transaction rejected otherwise there are already filled slots and new unconfirmed transaction with signer arrives, the fair share slots for account the cache calculated transaction fees eff. importance (importance max fs) fair share (eff. importance) exp occupies less slots than its fair share, the new unconfirmed transaction accepted. note that you can increase the chance that your new transaction accepted voluntarily increasing the transaction fees. figure shows the fair share slots versus the fill level the cache for effective importance attacker that tries occupy many slots cannot gain much using many accounts the importance each account will very low. could attack increasing his transaction fees but that will make him expend his funds higher rate. page fair share fill level figure fair share for effective importance page blocks and the block chain ever the moment shall say: beautiful moment, not pass away! then you may forge your chains bind me, johann wolfgang von goethe central element every crypto currency public ledger called the block chain that links blocks together. each nem block can contain transactions. since the blocks the chain and the transactions the blocks are ordered, the complete transaction history held the block chain. blocks are stored database permanent medium. nem calls the first block the chain the nemesis block. each block consists the following parts: the block version the block time stamp the public key the harvester (block creator) the signature for the block data the previous block hash the generation hash (needed for block creation) the block height the list transactions the following sections, the hash function always means the -bit sha hash function. block difficulty the difficulty for new block calculated from the difficulties and time stamps the last blocks. less than blocks are available, only those are taken into account. page block times average over blocks seconds block height figure main net average block times over blocks only one block available, then the block has predefined initial difficulty otherwise, the difficulty calculated from the last blocks the following way: (difficulty block (time create block difficulty (average difficulty) (average creation time) (new difficulty) the new difficulty more than greater smaller than the difficulty the last block, then the change capped additionally, difficulties are kept within certain bounds. the new difficulty clamped the boundaries greater than smaller than simulations and the nem beta phase have shown that the algorithm produces blocks with average time seconds. the slow change rate makes hard for attacker with considerably less than importance create better chain secret since block times will considerably higher than seconds for the beginning his secret chain. page block score the score for block derived from its difficulty and the time (in seconds) that has elapsed since the last block: score difficulty time elasped since last block (block score) block creation the process creating new blocks called harvesting. the harvesting account gets the fees for the transactions the block. this gives the harvester incentive add many transactions the block possible. any account that has vested balance least xem eligible harvest. check account allowed create new block specific network time, the following variables are calculated: h(generation hash previous block, public key account) interpreted -bit integer time seconds since last block (importance the account) difficulty for new block and from that the hit and target integer values: hit target the account allowed create the new block whenever hit otherwise and then normalizing the local trust values: sij sim cij define the local trust vector ~ci with components cij aggregating local trust values from time time nodes broadcast their local trust values other nodes. having received the local trust values from other nodes, node can calculate aggregate trust value for node weighing the local trust node has node with its own trust node tik cij cjk this can written matrix notation defining (ckj and ~ti having components tik ~ti ~ci define the iteration: ~ti+ ~ti then this will converge the left principal eigenvector the matrix under the assumptions that irreducible and aperiodic. guarantee the assumptions being valid, slightly change the iteration mixing portion the initial trust vector into the iteration: ~ti a)c ti- a~p otherwise where suitable otherwise and, finally, the matrix (lij can defined as: lij fij cij fim cim otherwise which incorporates both the reported trust values and the feedback credibility. now straightforward define iteration analog equation ~ti a)lt ti- a~p otherwise which converges the left principal eigenvector the underlying matrix the power iteration. the original eigentrust++ paper suggests using additional measures limit trust propagation between honest and dishonest nodes. the paper was written with file sharing networks mind. such networks, incomplete data shared (parts files) and cannot checked for validity. therefore, even honest nodes could distribute malicious data. nodes the nem network always download entities their entirety and verify their integrity before distributing them other nodes. nem network simulations have shown that the results without the additional trust propagation measures are good enough mitigate the presence malicious nodes. page honest data, honest feedback eigentrust++ uniform trust percentage failed calls percentage malicious nodes figure simulation with attacking nodes that are always dishonest benefits the reputation system having reputation system for nodes allows nodes select their communication partner according the trust values for other nodes. this should also help balance the load the network because the selection the communication partner only depends node's honesty but not its importance. simulations show that the algorithm reduces the number failed interactions considerably. malicious nodes only provide dishonest data and dishonest feedback they are easily identified (figure but even the malicious nodes collude give other malicious nodes high trust value and provide false data and feedback only certain percentage, the trust algorithm still cuts down the percentage failed interactions (figure page honest data, honest feedback eigentrust++ uniform trust percentage failed calls percentage malicious nodes figure simulation with attacking nodes that are sometimes dishonest page proof-of-importance was hot, the night burned chrome. william gibson roof-of-importance (poi) the name the block chain consensus algorithm used nem. each account assigned importance score that proxies its aggregate importance the nem economy. accounts with higher importance scores have higher probabilities harvesting block (see section blocks and the block chain). because all transactions are publicly available nem, the transaction graph the nem economy can calculated exactly. the topology the transaction graph can used input into the importance account. the insight that the transaction graph can used for elucidating the importance account the key innovation proof-of-importance. the nem block chain platform allows all transactions transparently viewed. this information about value transfers between accounts can used determine rating for the importance accounts. the intuition that not all nodes graph have the same salience, importance, not new. the literature the graph theory community well established for computing the importance nodes graphs the areas search [], social networks [], street networks [], and neuroscience [], among others. building off this intuition, one nem's core innovations use graph theoretic measures fundamental input into block chain consensus. the outlink matrix that defines the transaction graph centrally important and used the poi calculation. eligibility for entering the importance calculation eligible for entering the importance calculation, account must have least vested xem. all accounts owning more than vested xem have non-zero importance score. with supply ,,, xem, the theoretical maximum number accounts with non-zero importance practice, the number actual accounts with non-zero importance not expected approach the theoretical max due inequalities held xem and also the temporal costs associated with vesting. nem becomes very popular, threshold vested xem could undesirable. necessary, this number could updated the future via hard fork, which the same procedure for adjusting transaction fees and other parameters related harvesting. page the outlink matrix suppose the poi calculation done height accounts that have vested balance least xem height are eligible part the poi calculation. for those accounts, nem collects all transfer transactions that satisfy the following conditions: transferred amount least xem happened within the last blocks (approximately days) recipient eligible part the poi calculation too (see subsection eligibility for entering the importance calculation) for each such transaction that transferred amount uxem from account account and happened height hijk weight calculated according the following formula: wijk hijk amount exp ln(.) where [x] denotes the floor function. the graph figure amount decay xem illustrates how transaction amount xem weighted over time. these values are aggregated weij wijk setting oeij weij weji weij otherwise finally, the outlink matrix comprised components oij oij oij oeij otherwise the outlink matrix element oij thus describes the weighted net flow (which set negative) xem from during the (approximately) last days. this means that only net transfers contribute account's importance. page weight days figure amount decay xem page figure plot the nem transaction graph (outlink matrix) april, containing harvesting-eligible accounts. page ncdawarerank there are many ways determine the salience nodes network, and pagerank one method. ncdawarerank similar pagerank, where the stationary probability distribution ergodic markov chain calculated ncdawarerank additionally exploits the nearly completely decomposable structure large-scale graphs information flows adding inter-level proximity matrix extra term, the inter-level proximity matrix models the fact that groups nodes are closely linked together form clusters that interact with each other. this allows ncdawarerank converge faster than pagerank while also being more resistant manipulation scores, because the rank for nodes within the same level will limited. shown matrix notation, ncdawarerank calculated as: oep mup u)p, where: the the the the the the outlink matrix inter-level proximity matrix teleportation matrix ncdawarerank fraction importance that given via outlinks fraction importance given proximal accounts this definition the same for pagerank, only with the addition and for nem, and the details how each these variables calculated are follows. let the set all harvesting-eligible accounts. for the set accounts that have received more value transfers from account than have sent nearly completely decomposable (ncd) partitions are defined ..., such that for every there unique such that the proximal accounts each khu are thus defined as: khu a(w) w(ugu and denotes the number ncd blocks khu page the definition the outlink matrix described subsection the outlink matrix. guarantee convergence, must irreducible, column-stochastic matrix. this accomplished dispersing the rank dangling accounts (accounts without outlinking value transfers) that every account has non-zero teleportation probability. the inter-level proximity matrix calculated clustering the transaction graph (described subsection clustering the transaction graph) define each ncd block and then determining the proximal accounts for each cell mv,u |a(v) khu otherwise the teleportation matrix calculated as: ev> where teleportation probability vector and the vector with all components set practically, ncdawarerank calculated via the power iteration method follows: ncdawarerankr (i) |g| oik ncdawarerankr- (k) mik ncdawarerankr- (k) where oki denotes the row for column and mki the row for column the algorithm continues until the change ncdawarerank between iterations less than specified ncdawarerank (i) ncdawarerank (i) core nodes are used for pivoting and expanding clusters and are defined follows: k,u (u) |n (u)| where the minimum number epsilon neighbor accounts that account must have considered core. during clustering, clusters are centered (pivoted) around core accounts. the initial members the cluster are the members this means that controls the smallest possible size cluster. nem, and account has direct structure reachability, -,u with account for given and core and member (u): -,u k,u (u) (u). the scan algorithm, accounts that are core are set pivots and then clusters are expanded including accounts with direct structure reachability (equation clustering the transaction graph). this requires computing the structural similarity with each neighbor and the neighbors' neighbors. the improved version scan only looks the pivot accounts and accounts that are two-hops away from the pivot accounts. accounts two-hops away from account h(u), are defined follows: h(u) |(u, (v, e)} page where account account, such that (u) {u}. for each core account that two-hops away from the pivot, new cluster generated and pivoted around it. all the core account's epsilon neighbors (n are added the new cluster. when computing the accounts that are two-hops away, accounts with direct structure reachability from the pivoted node are removed from the calculation. when expanding the two-hops away accounts, the accounts are processed, such that: h(un |(u, (v, (ui h(ui after all accounts the graph have been processed, all nodes are analyzed. account belongs multiple clusters, then those clusters are merged. afterwards, any account that not cluster marked hub connects two more clusters outlier does not. the use the two-hop away nodes expand the clusters reduces the computation cost clustering because the calculation structural similarity the slowest part the algorithm. the computed clusters are also used determine the levels the ncdawarerank inter-level proximity matrix, these clusters are representative the nearly completely decomposable nature the transaction graph. calculating importance scores the importance score, ps, calculated follows: (normalize (max(, swo pwi )kh, where: kvk the vested amount xem the weighted, net outlinking xem the ncdawarerank score weighting vector that considers the structural topology the graph are suitable constants normalize (v) is: page considers the topology the graph and assigns higher weight nodes that are members clusters, rather than outliers hubs. outliers and hubs are weighted their score, whereas nodes that are clusters are weighted nem, and taken together, the information about vested balance, sent xem, and transaction graph-topology form the basis for heuristic evaluation the importance accounts the nem economy. furthermore, since importance cannot arbitrarily manipulated gamed (see subsection resistance manipulation), importance scores are useful for purposes other than just block chain consensus. for example, they can interpreted form reputation. because all importance scores sum unity, they represent finite quantity that can used for purposes such voting preventing spam. this allows even anonymous actors interact with each other because not possible for people gain control creating many pseudonymous identities. resistance manipulation the use ncdawarerank, vested balance, decayed and weighted outlinks, and summation unity the calculation importance scores makes the scores resistant arbitrary manipulation. sybil attack peer-to-peer systems, faulty malicious entities can often present themselves multiple identities order gain control system []. this called sybil attack. nem, there financial reward for harvesting blocks because harvesters receive fees (see section subsection block creation), and accounts with higher importance scores have higher probabilities harvesting block. result, attackers are expected highly motivated attempt sybil attacks. sybil-style attacks were considered when designing the poi algorithm. the usage ncdawarerank, vested balances, and net decaying outlink weights makes the importance score calculation resistant sybil attacks. with respect the importance score calculation, some the potential vectors for sybil attackers include: account splitting and transacting among split accounts boost the ncdawarerank score account splitting and transacting with random accounts page sending xem between acounts loop boost the outlink score (see subsubsection ..: loop attack) the following mitigations are place counter sybil attacks. use ncdawarerank instead pagerank graph-theoretic importance metric the inter-level proximity matrix the ncdawarerank algorithm makes the algorithm more resistant link spamming than pagerank []. for web pages, pagerank commonly spammed creating many sites that all link main site, magnifying the pagerank the main site []. the analog this nem would for account send portions its balance other accounts and then send all the xem back the main account. vest the balance accounts over temporal schedule that qualitatively "slow" for humans requiring several weeks fully vest inflows into account makes impossible acquire large amounts xem and then immediately attack the network. use net-outlinking xem for outlink score calculation the net-outlinking xem used the importance score calculation. there advantage sending xem around many accounts because the inlinking xem sent the account will cancel out the outlinking xem. decay the weight outlinking value transfers outlinking value transfers are decayed over time. sending xem another account will only give temporary boost the importance score. normalize importance scores sum unity the actions others affect your importance score because all scores sum unity. require minimum balance vested xem required for harvesting requiring least vested xem harvest creates bounds the number accounts that could theoretically involved sybil attacks. choose relatively small values for and this ensures that the largest component importance the amount vested xem, which cannot exploited. taken together, these countermeasures make proof-of-importance resistant sybilstyle attacks. test this, performed simulations with between and colluding sybil accounts. figure shows the results the simulation for conditions: page colluding accounts sending xem loop each other colluding accounts all sending xem common, colluding account colluding accounts sending xem accounts randomly figure shows, after adding small number accounts, sybil attacker does not gain much importance adding even thousands additional accounts. although the sybil attacker gains more importance than the honest actor, the gain limited and bounded the poi calculation. some actors can boost their importance splitting their accounts sending transactions other accounts mimic economic activity. because poi scores sum unity, other rational actors should take the same actions. this would cause the expected benefit disappear. compared pow mining, the advantage that can gained gaming poi minimal. pow, miners who buy specialized mining hardware have large advantage over those who use only commonly available video cards. this writing, equal amount money can buy either two video cards with combined mhash/s mining power specialized asic miner with mhash/s. the difference between the mining power and approximately poi, due the constraints the algorithm, actor perfectly gaming the system will get advantage well less than order magnitude. other words, poi gaming will not result significant qualitative advantage over actors with the same balance who nothing. for the case where controlled accounts all send common master account, figure shows that the importance can actually decrease when more nodes are involved attack. for figure the importances decreased after threshold accounts were combined the attack because the graph topology changed such that the attacking nodes were longer the same cluster. this caused the structural topology weight, kh, reduced from loop attack the loop attack, accounts controlled the same entity send xem around via transfer transactions loop boost their importance score. while the outlinking xem from account large portion the importance score calculation, the outlinking xem the net outlinking xem, such that inlinking xem account subtracting from the outlinking xem. thus sending xem around loop millions times will not give you higher net outlinking xem score than sending out just once. page (a) (b) importance score honest sybil number colluding sybil accounts (log scale) (c) figure importances graphed for two actors with million xem with combined million xem sent via outlinking value transfers. the honest actor keeps his xem one account, whereas the sybil actor controls multiple accounts and: (a) sends xem around loop between controlled accounts, (b) vests the xem controlled accounts and then sends them all single master account, and (c) sends xem from each controlled account random account. importance scores are plotted the y-axis and the number colluding accounts for the sybil actor plotted log scale the x-axis. for (c), shading denotes from trials and solid lines denote the mean. page nothing-at-stake problem theoretically, algorithms for probabilistic byzantine consensus that not require the expenditure external resources are subject the nothing-at-stake problem the nothing-at-stake problem theoretically exists when the opportunity cost creating block negligible. other words, the cost creating block low that easy create block for all known forks block chain (including those forks that were selfcreated secret). contrast, the nothing-at-stake problem does not exist when proof work used for consensus because creating block using such consensus mechanism resource-intensive. nem, the cost creating block negligible. mitigate the nothing-at-stake problem, nem caps the change block difficulty and also limits the length the chain that can unwound during fork resolution. described subsection block difficulty, the block difficulty change rate capped maximum attacker has considerably less than the harvesting power the network, this will cause the block creation time the attacker's secret chain much higher than that the main chain the beginning. this large time difference will make unlikely for the attacker's chain better and accepted. addition, the block chain unwind limit blocks (see subsection block chain synchronization), which prevents long-range forks from harvesters working multiple chains. comparing importance stake subsection calculating importance scores shows, the vested balance account large component the importance score. taking the vested balance the "stake" used currencies implementing the proof-of-stake (pos) algorithm, could argued that pos and poi are similar. order explore the differences and similarities between pos and poi, the nem and bitcoin transaction graphs were analyzed. bitcoin was chosen due the relatively large size its user base and transaction graph. april the nem transaction graph had harvesting-eligible accounts (see subsection eligibility for entering the importance calculation). october approximately one month data from the bitcoin network was downloaded and analyzed. accounts were harvesting-eligible when btc amounts were normalized nem. amount normalization was done multiplying the btc amounts the market cap ratio. thus, btc was the minimum amount vested btc for account considered harvesting-eligible. block heights were normalized nem multiplying see vitalik buterin's blog post the subject for good overview: https://blog.ethereum.org/ ///proof-stake-learned-love-weak-subjectivity/. page figure (a) shows importance scores and vested balances plotted log scale for each the harvesting-eligible accounts (sorted vested balance, ascending) the nem transaction graph, and (b) for the harvesting-eligible accounts the bitcoin transaction graph. can seen, while the vested balances are monotonically increasing, the importance scores are non-monotonic, demonstrating that accounts with lower vested balances are able gain higher salience poi than pos both transaction graphs. figure shows the plotted nem transaction network graphs for both normalized importance scores and vested balances order give overview the qualitative differences between poi and pos. normalization was done make the differences between scores with low and high values more visible. was accomplished scaling the importance scores and vested balances sum unity, taking the absolute value the logarithm that, mapping exponential function, and then rescaling sum unity. can seen the graph, vested balances give larger weight fewer nodes, whereas importance scores have less noticeably larger nodes. quantify the differences account saliences, all the accounts for nem and bitcoin were ranked (densely; accounts with the same score/balance were given the same rank) based vested balances and importance scores and looked the differences ranks between the two metrics. table differences between nem account ranks for importance scores vs. vested balances. shows the results for accounts the nem transaction graph and table differences between bitcoin account ranks for importance scores vs. vested balances. shows the results ranking bitcoin accounts. overall, nem accounts ranked importance scores were ranked approximately ranks lower than when ranked vested balances. the richer half accounts decreased average ranks while the poorer half decreased average ranks. bitcoin accounts were ranked average ranks lower when ranked with importance scores than when ranked vested balances. the poorer half accounts gained average ranks and the richer half lost average ranks. this suggests that poi gives less salience overall richer accounts than pos. table differences between nem account ranks for importance scores vs. vested balances. average rank increase for importance stakes (poor half): average rank increase for importance stakes (rich half): average rank increase for importance stakes: page table differences between bitcoin account ranks for importance scores vs. vested balances. average rank increase for importance stakes (poor half): average rank increase for importance stakes (rich half): average rank increase for importance stakes: page importances stakes normalized score (log) nth account (stake, ascending) (a) importances stakes normalized score (log) nth account (stake, ascending) (b) figure importance scores and vested balances for accounts the harvesting-eligible subset the (a) nem and (b) bitcoin transaction graphs are plotted. importance scores and vested balances were normalized sum unity (.), with accounts sorted ascending order. graphs are plotted the y-axis with log scale, allowing clear comparison between stake and importance scores, and accounts are the x-axis. page (a) (b) figure nem transaction graphs where node sizes denote normalized (a) importance scores and (b) vested balances. normalization described subsection comparing importance stake. page time synchronization you spend too much time ephemeras. the majority modern books are merely wavering reflections the present. they disappear very quickly. you should read more old books. the classics. goethe. franz kafka ike most other crypto currencies, nem relies time stamps for transactions and blocks. ideally, all nodes the network should synchronized with respect time. even though most modern operating systems have time synchronization integrated, nodes can still have local clocks that deviate from real time more than minute. this causes those nodes reject valid transactions blocks, which makes impossible for them synchronize with the network. therefore needed have synchronization mechanism ensure all nodes agree time. there are basically two ways this: use existing protocol, such ntp use custom protocol the advantage using existing protocol like ntp that easy implement and the network time will always near real time. this has the disadvantage that the network relies servers outside the network. using custom protocol that only relies the network itself solves this problem, but there trade off. impossible guarantee that the network time always near real time. for overview over different custom protocols see for example []. nem uses custom protocol order completely independent from any outside entity. gathering samples each node the network manages integer number called offset which set start. the local system time milliseconds incremented the offset (which can negative) the network time (again milliseconds) the node. after the start node completed, the node (hereafter called local node) selects partner nodes for performing time synchronization round. only nodes that expose minimum importance are considered partners. page partner node network time response request local node network time figure communication between local and partner node. for all selected partners the local node sends out request asking the partner for its current network time. the local node remembers the network time stamps when the request was sent and when the response was received. each partner node responds with sample that contains the time stamp the arrival the request and the time stamp the response. the partner node uses its own network time create the time stamps. figure illustrates the communication between the nodes. using the time stamps, the local node can calculate the round trip time rtt and then estimate the offset between the network time used the two nodes rtt this repeated for every time synchronization partner until the local node has list offset estimations. applying filters remove bad data there could bad samples due various reasons: malicious node can supply incorrect time stamps. honest node can have clock far from real time without knowing and without having synchronized yet. the round trip time can highly asymmetric due internet problems one the nodes being very busy. this known channel asymmetry and cannot avoided. page filters are applied that try remove the bad samples. the filtering done steps: the response from partner not received within expected time frame (i.e. ms) the sample discarded. the calculated offset not within certain bounds, the sample discarded. the allowable bounds decrease node's uptime increases. when node first joins the network, tolerates high offset order adjust the already existing consensus network time within the network. time passes, the node gets less tolerant with respect reported offsets. this ensures that malicious nodes reporting huge offsets are ignored after some time. the remaining samples are ordered their offset and then alpha trimmed both ends. other words, both sides certain portion the samples discarded. calculation the effective offset the reported offset weighted with the importance the boot account the node reporting the offset. this done prevent sybil attacks. attacker that tries influence the calculated offset running many nodes with low importances reporting offsets close the tolerated bound will therefore not have bigger influence than single node having the same cumulative importance reporting the same offset. the influence the attacker will equal the influence the single node macro level. also, the numbers samples that are available and the cumulative importance all partner nodes should incorporated. each offset therefore multiplied with scaling factor. let the importance the node reporting the j-th offset and viewsize the number samples divided the number nodes that were eligible for the last poi calculation. then the scaling factor used scale min viewsize this gives the formula for the effective offset scale page coupling round figure coupling factor note that the influence account with large importance artificially limited because the viewsize caps the scale. such account can raise its influence macro level splitting its nem into accounts that are not capped. but, doing will likely decrease its influence individual partners because the probability that all its split accounts are chosen time-sync partners for any single node low. coupling and threshold new nodes that just joined the network need quickly adjust their offset the already established network time. contrast, old nodes should behave lot more rigid order not get influenced malicious nodes newcomers too much. order enable this, nodes only adjust portion the reported effective offset. nodes multiply the effective offset with coupling factor build the final offset. each node keeps track the number time synchronization rounds has performed. this called the node age. the formula for this coupling factor is: max e-.a where max(nodeage this ensures that the coupling factor will for rounds and then decay exponentially finally, node only adds any calculated final offset its internal offset the absolute page value above given threshold (currently set ms). this effective preventing slow drifts the network time due the communication between nodes having channel asymmetry. page network for what it? nothing but little blood and bones; piece network, wrought out nerves, veins, and arteries twisted together. marcus aurelius nem network comprised nis nodes. each node associated with single primary account, which used authenticate responses that node. this prevents attacker from impersonating node without having its private key even can spoof the node's address. each nis node has the following configuration settings: nis.nodelimit the number other nodes which the local node should broadcast information nis.timesyncnodelimit the number other nodes the local node uses synchronize its clock section time synchronization typically, nis.timesyncnodelimit should larger than nis.nodelimit order allow better time smoothing. this isn't too expensive because the data transferred part time synchronization relatively small. node protocol nis nodes communicate amongst themselves using proprietary binary format default. this format minimizes network bandwidth compacting requests and processing reducing the cost serialization and deserialization. fact, all nis apis support requests encoded either the nem proprietary binary format json. order prevent impersonation-based attacks, nis nodes engage two part handshake when communicating: the local node sends the request data and random -byte payload the remote node. the remote node signs the random payload and sends the signature along with the requested response data back the local node. the local node checks the signature and only processes the response data can verify that the remote node signed the random payload. page partner node network time response random data signature request random data local node network time figure communication between local and partner node. node startup when nis node launched, the node processes the block chain and caches some data memory improve online performance. once the processing finished, the node still not connected the network because not yet booted. non-booted node not associated with account. this prevents from being able sign responses and prevents other nodes from being able verify its identity. order boot node, the private key nem account must supplied the node. this account the primary account associated with the node. delegated account can used boot node order better protect the private key the real account (see subsection importance transfer transactions). node discovery once node booted, connects the nem network and starts sharing information with other nodes. initially, the node only aware the well-known nodes. these nodes are the same the pre-trusted nodes described subsection local trust value. over time, the node becomes aware more nodes the network. there are typically two ways this happens: via announcement refresh. announcement periodically, node announces itself its current partner nodes and includes its local experience information the request. the node unknown the partner, the partner marks active and updates the node's experiences. the node known the partner, the partner only updates the node's experiences but does not change its status. page refresh periodically, node asks its current partners provide updated information about themselves and the state the network. first, the node requests update information about the remote node. successful, the local node will update the remote's endpoint (necessary support dynamic ips) and metadata. this step fails any the following occur: the remote node returns valid request from different node the remote node not compatible with the local node (e.g. the remote node testnet but the local node mainnet) success, the remote node asked provide list all its current partner nodes. order prevent evil node from providing incorrect information about good nodes and causing them blacklisted, the local node attempts contact each reported partner node directly. important note that node's metadata will only updated metadata provided that node itself. optimization, blacklisted nodes are not refreshed. node can temporarily blacklisted returns fatal error the local node cannot connect it. periodically, blacklisted nodes will removed from the blacklist and will allowed participate the refresh operation again. the original blacklisting was due non-transient error, the node will likely blacklisted again. node selection over time, result the node discovery process, the local node will become aware more nodes the network. eventually, the number known nodes (including both well-known and other nodes) will much greater than the number partner nodes. periodically, node recalculates its partner nodes. when this recalculation occurs, all known nodes are eligible become partner node, including nodes that have been detected busy. with default settings, this recalculation will occur more frequently than the recalculation trust values. default, trust values are recalculated every minutes. the known nodes are weighted their trust values and the partner nodes are randomly selected from among them. nodes with larger trust values (which are more likely good nodes) are more likely chosen partners. nodes that have been minimally interacted with typically have trust values close order give these nodes page chance prove themselves and build trust, they are effectively given small boost trust that they have the opportunity selected and participate the network. trust evenly distributed among nodes with less than interactions. order ensure that the network connected, one adjustment the random process made. the local node well-known node, additionally connected with all online well-known nodes. the local node not well-known node, additionally connected with one random, online, well-known node. this ensures that all nodes are actively partnering with least one well-known node. page references lars backstrom and jure leskovec. supervised random walks: predicting and recommending links social networks. proceedings the fourth acm international conference web search and data mining, pages acm, daniel bernstein, niels duif, tanja lange, peter schwabe, and bo-yin yang. highspeed high-security signatures. cryptographic hardware and embedded systems ches international workshop, nara, japan, september october proceedings, pages john douceur. the sybil attack. peer-to-peer systems, pages springer, nadav eiron, kevin mccurley, and john tomlin. ranking the web frontier. proceedings the international conference world wide web, pages acm, xinxin fany, ling liu, mingchu li, and zhiyuan su. eigentrust++: attack resilient trust management. tayfun gurel, luc raedt, and stefan rotter. ranking neurons for mining structure-activity relations biological neural networks: neuronrank. neurocomputing, ():-, bin jiang. ranking spaces for predicting human movement urban environment. international journal geographical information science, ():-, kamvar, schlosser, and garcia-molina. the eigentrust algorithm for reputation management networks. proceedings the international conference world wide web, pages a.n. langville and c.d. meyer. google's pagerank and beyond: the science search engine rankings. princeton university press, princeton, usa, athanasios nikolakopoulos and john garofalakis. ncdawarerank: novel ranking method that exploits the decomposable structure the web. proceedings the sixth acm international conference web search and data mining, pages acm, lawrence page, sergey brin, rajeev motwani, and terry winograd. the pagerank citation ranking: bringing order the web. technical report stanford infolab, stanford, usa, november page sirio scipioni. algorithms and services for peer-to-peer internal clock synchronization. phd thesis, universit'a degli studi roma ,,la sapienza", shiokawa, fujiwara, and onizuka. fast structural similarity graph clustering. the forum data engineering and information management (deim), xiaowei xu, nurcan yuruk, zhidan feng, and thomas schweiger. scan: structural clustering algorithm for networks. proceedings the acm sigkdd international conference knowledge discovery and data mining, pages acm, page