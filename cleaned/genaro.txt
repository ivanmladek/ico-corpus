genaro network yellow paper genaro network roadmap towards multi-source data governance framework yellow paper v.. page genaro network yellow paper abstract the genaro network new public blockchain platform based peer-to-peer encryption and sharing. the platform aims realize highly efficient node management the public chain based pos (proof stake) and spor (sentinel proof retrievability). the vision genaro establish new medium distributed and encrypted storage, and enable each user use and share data, and establish abundant distributed applications (dapps) the blockchain and provide stable support for these. compared with other public chains, genaro has the following advantages: genaro modified the use file sentinels better suit distributed systems through the combination pos and spor, thus enhancing the ability defend against replay attacks; the design chain-style pos, genaro studied famous pos methods such casper (cffg, ctfg) tendermint, and ouroboros, analyzed the major ways attacking pos and proposed relevant schemes; and terms management structure, genaro combines the proof data integrity and pos, and provides effective methods defense against potential problems pos. addition, terms the data structure the public chain, genaro has developed the gsiop protocol line with up-to-date methods storage encryption, settle different layers data usage. finally, terms adding data, genaro has also added relevant order sets. table contents genaro's vision.................................................. storage network ............................................... file sharing based proxy recryption................................................ new opcodes ................................. new instructions..................................... new special transaction........................ dht-distributed hash table .................. kad network and nodes ....................... xor matrix and distance calculation ... node status contact ............................ kademlia agreement ............................... flp impossible features......................... lookup algorithm ................................... cap theorem......................................... cache ....................................................... point-to-point encryption storage bucket refresh ........................................ key-value redistribution ........................ consensus (spor) ................................. genaro public chain.......................................... searchable encryption.............................. genaro i/o streaming protocol consensus governance structure.................... chain style pos...................................... data management structure design....... summary and outlook..................................... references................................................................. (gsiop).................................................... page genaro network yellow paper genaro's vision genaro public chain that combines peer-to-peer encrypted storage. the original intention the design allow data shared after encryption, giving users different data rights, and ultimately allowing rich ecosystem decentralized applications (dapps) built the public chain. now, most dapps are centered around transactions the trading market, gambling, and gaming. storage network dht-distributed hash table [], that is, peer-to-peer, can said very concentrated embodiment the internet philosophy: common participation, transparent openness, and equal sharing. there are many applications based technology, including file sharing, instant messaging, collaborative processing, streaming media communication, etc. []. through the contact, analysis and understanding two data-related features dapps: there limited data storage the chain and off-chain data not directly usable, making the dapp not ubiquitous the current mobile phone web app, resulting narrow functionality for the blockchain. genaro designed allow data have decentralized storage medium and complement the functionality its encrypted data, incorporating the idea encrypted data processing via the blockchain. achieve this goal, genaro's system designed three parts: the storage network, the public chain, and the consensus governance (figure this yellow paper will elaborate these three elements. these applications, the essence new network communication technology. this new communication technology breaks with traditional structures, becoming gradually decentralized and flattened, thus moving towards the future trend equal nodes all working together. the application file sharing (bts/emules, etc.) the most concentrated embodiment technology. genaro file sharing network entry point, around file network system, and its operability combined with the blockchain formula algorithm design new flat, decentralized cloud while retaining the blockchain's open, transparent characteristics. the development the file sharing network generally has the following stages, including the network the tracker server, the pure dht network without any server, and the hybrid network. the distributed hash table (dht) distributed storage method. dht, type information that can uniquely identified key value stored multiple nodes according certain convention/protocol, which can effectively avoid the issues the single failure "centralized" server (such tracker). distinct from centralized node server, each node the dht network does not need store the information the entire network, but only stores data from its neighboring subsequent node, figure genaro system architecture which greatly reduces the bandwidth occupation and resource consumption. the dht network also backs redundant information the node closest the keyword, avoiding the single node failure problem. page genaro network yellow paper there are many techniques/algorithms for implementing the nodes the kad dht storage network include the dht, such chord [], pastry [], kademlia [], etc. genaro uses the kademlia algorithm because file following features: sharing software such and derivatives (mainline, btspilits, btcomet, utorrent), emule and emule mods the nodeid needs bits bytes the kad; (verycd, easy emules, xtreme) are based this algorithm. contact contains nodeid (nodeid), address(string), udp since the protocols implemented each these are not the same, there will incompatibility issues. uses python's kademlia implementation called khashmir. emule uses the c++ kademlia implementation called kad. among the port number; many protocols, genaro's implementation based emule's kad, which the dht network implementing kad bucket [vaugekconst]*contact used the routing nodes. bucket can contain nodes and all nodes will disappear after hour; protocol, for the reason that the point-to-point library and vaugekconst set the storage network are isomorphic. the following introduction, will gradually explain the advantages the router contains contact and kbucket. kbucket has kademlia algorithm itself. kademlia technology, often referred third-generation technology, universal protocol for all distributed peer-to-peer computer networks. kademlia defines the structure the network and plans communication between nodes and specific information interaction processes. kademlia, network nodes use udp communicate, and distributed hash table used store data. each node has its own id, which used identify the bucket each bit the id. kademlia uses key values identify nodes and data the kad network. the key value kad not transparent and has length bits. each computer that comes will have key, called nodeid, generated -bit keyvalue space. since the kad stores content (keyvalue) pair, data the kad dht also independent the space corresponding the key the -bit key. node itself and also help implement kademlia algorithms and processes. the beginning, node not linked any other nodes. are selectively removed and then organized inside the kad network and nodes when new node registered, the nearest node will find the link this node and save the new nodeid. the contacts bucket when the store overflows. the way find nodeid from node find another near node from known routing table until the requested node found. kad provides several features that other dhts cannot provide spontaneously, including: figure kad network kad minimizes the amount intro information node; the configuration information includes node information and presence information the network, and page genaro network yellow paper automatically propagated through the relationship side the kad, the nodes store contact information for routing effects the search for the key; information. each uint []) public file; file[ds].push(bucketid); //check greater than months sgas(ds,bucketid));assert(ds.update); //check the fragment size more than require(ds.sused gb); check the space require(ds.ssize gb); check the total number file fingerprints owned address more than check_sentinel (user_address)> page genaro network yellow paper new special transaction the special transaction added accommodate the bet the public chain and the storage verification attribute. the the distributed processes way that will determine specific value, that is, the consensus permits participants vote for specific value. given series processors, each following special transactions are added the system: with initial value: bet transactions (user-initiated transactions). its role all non-error handling eventually reaches value; all processing decisions things this value; the value determined needs raised some support the action betting pos. the user uses the balance his account place bet. after the bet, the amount the bet will added into the user's stake attribute. storage weight synchronization transaction (storage network initiated transaction). its role synchronize the stored results the public chain aid. the special account specified the storage network initiates synchronous transaction the heft value, synchronizing the heft the chain. the transaction which the user purchases the storage space. its main role support users directly pay the storage capacity corresponding price the chain. the transaction, the purchase amount determined according the space parameter provided the user, and the successful deduction the amount indicates that the transaction successful. during the transaction process, some records expired historical storage space can cleaned up. after purchasing the storage space, some traffic can bundled according the purchase quota. the transaction which the user purchases the traffic. traffic the store represents upload and download traffic. the traffic purchased the user will added the total traffic, for example, space purchased and traffic can downloaded times. processors. these three characteristics are called termination, agreement, and validity. any algorithm with these three characteristics can solve the problem consensus. termination and agreement are relatively easy explain. just need avoid operations from the wrong nodes. for validity, need remove the nodes that give the wrong choice regardless the initial value. this algorithm certainly satisfies the requirements termination and agreement, but useless. flp impossible features the flp (fischer, lynch and patterson) impossibility actually involves slightly weaker form consensus: for termination, only some non-erroneous process decisions are sufficient. it's important note that having powerful process determine value not enough, because the process may fail and the other will have take where is, even weak termination meet the requirements. the conclusion flp's impossible feature that error detection non-synchronous situations cannot detect the problem the processor without borders and then return specific value, that is, impossible judge whether the consensus governance before introducing genaro's consensus, first wish establish some common-sense points about consensus processor down not replying for long time. has been proven research that asynchronous algorithm can guarantee certainty when protecting downtime errors and can not guaranteed without downtime. mechanisms. the consensus basically there organize page genaro network yellow paper flp's impossible feature proves that the asynchronous theorem needs considered advance, that is, the algorithm without any validation "-" can guarantee that case consistency, the finality the block can executed synchronously. and the case availability, only one the process will terminated soon the downtime occurs and that still correct when similar error occurs. because the case asynchronous, the asynchronous distributed system will converge the state the system "two-valued state". this state, any input input will destroy the balance, but the end will back the dual value state. this way, the system proven infinite and non-terminal, the system will into infinite loop. asynchronous execution termination system can implemented. this system, the flp impossible feature needs emphasized. that is, the cap, after the fault tolerance guaranteed, choose synchronization (class bft consensus) asynchronous (nakamoto chain consensus). the end the loop completely out this state, which means that you need add state that can guided. faulttolerant consensus can done vote, but still have hard time proving that can end, the need between the only part that can't guaranteed the cap the same time, need discuss separately. the design genaro, must give priority the availability the chain, the result guarantee possibility. can that is, achieve the multi-node high concurrency standard prove through process, but need logically perfect guarantee, can't reach it. the design the genaro the public chain. this case, need abandon the consistency feature and preserve the system fault consensus, considering that there such thing the ability break the two-valued state without adding additional information, need add additional information when designing the forked approach the chain consensus. what added here storage related system fault tolerance tolerance. the general way reduce fault tolerance through special data state checking, that is, through special broadcast that special transaction; and another timeout specific protocol fault tolerance. information for genaro. distributed storage system, when system failure causes information lost duplicated and there malicious node (ie, error information), the consensus problem called cft (crash fault tolerance). when there cap theorem genaro must follow the cap theorem the design blockchain consensus, which specific distributed malicious node, called bft (byzantine fault computer data system. the cap theorem also known tolerance). order solve the problem byzantine fault tolerance common distributed systems, genaro draws brewer's theorem. the theorem proves three parts that cannot guaranteed simultaneously for distributed the industry's most classical pbft (practical byzantine fault tolerance) algorithm, which was proposed miguel computer system: consistency, availability, and partition tolerance []. castro and barbara liskov []. the core this consensus design asynchronous approach consistency and byzantine fault tolerance. then need this consistency not primarily used for acid database consistency. the specific performance feature that each understand and graft pbft the compatibility issue byzantine fault tolerance the design. the previous read has the latest written result error. availability means that every time you pass request the system, you clarification the cap theorem, has been explained that the chain consensus blockchain also ap-type get reply, not error, but you don't need ask for this the latest one. the partition tolerance that when the distributed system, that say, the consistency different information between some nodes the network lost, the and the byzantine fault-tolerant part the asynchronous case similar. the following brief description pbft. system still works. when designing consensus, the cap page genaro network yellow paper pbft assumes asynchronous distributed system model current primary. client sends request what and node failures occur independently. pbft uses encryption prevent spoofing attacks and replay attacks believes the current primary using point-to-point message. and detect corrupted information. the information includes the public key signature, the message validation code, and the message digest generated the collision-free hash function. all nodes know the public key the other node for signature verification. the pbft algorithm form state machine replication: the client waits for replies with valid signatures from different replicas, and with the same and before accepting the result this ensures that the result valid, since most replicas can faulty. the client does not receive replies soon enough, broadcasts the request all replicas. the request has the service modeled state machine that replicated across different nodes distributed system. each state already been processed, the replicas simply re-send the reply; replicas remember the last reply message they machine replica maintains the service state and implements the service operations. the replicas move through sent each client. otherwise, the replica not the primary, relays the request the primary. the succession configurations called views view primary does not multicast the request the group, one replica the primary and the others are backups. will eventually suspected faulty enough replicas cause view change. denote the set replicas the maximum number replicas that may faulty and view changes are carried out when appears that the primary has failed. pbft algorithm works roughly follows: client sends request invoke service operation the primary, and timestamp used ensure exactly once semantics for the execution client requests; the primary atomically multicasts the request all the figure pbft algorithm process backups. when the primary receives client request, starts three-phase protocol atomically multicast the request the replicas: pre-prepare, prepare, and commit. the pre-prepare and prepare phases are used totally order requests sent the same view even when the primary, which proposes the ordering requests, faulty. the prepare and commit phases are used ensure that requests that commit are totally ordered across views. replica sends the reply the request directly the client. the reply has the form where the current view number, the timestamp the corresponding request, the replica number, and the result executing the requested operation, allowing the client track the view and hence the the resiliency pbft algorithm optimal: the minimum number replicas that allow asynchronous system provide the safety and liveness properties when replicas are faulty. safety means that the replicated service satisfies linearizability: behaves like centralized implementation that executes operations atomically one time. safety requires the bound the number faulty replicas because faulty replica can behave arbitrarily, e.g., can destroy its state. safety provided regardless how many faulty clients are using the service (even they collude with faulty replicas): all operations performed faulty clients are observed consistent way non-faulty clients. the page genaro network yellow paper safety property insufficient guard against faulty clients, integration and complementary advantages. here focus e.g., file system faulty client can write garbage data some shared file. however, pbft limit the amount sentinel, which means that this part the information our focus the whole process. compared other damage faulty client can providing access control: authenticates clients and deny access the client issuing consensus mechanisms for replacing pow content, such design will have lower consumption, because the essence request does not have the right invoke the operation. also, consensus verify the hash combination. this part the services may provide operations change the access permissions for client. since the algorithm ensures that the auxiliary information then given the corresponding heft the chain governance, which means that our governance effects access revocation operations are observed consistently all clients, this provides powerful not simple stake and offline governance. use the storage integrity verification algorithm audit the mechanism recover from attacks faulty clients. contribution storage nodes the chain and combine the online governance stakes gradually optimize and pbft algorithm does not rely synchrony provide maintain the stability the system. the advantage this safety. therefore, must rely synchrony provide liveness; otherwise could used implement consensus approach that does not interfere with the stability the system due some uncertainties under the chain. spor asynchronous system, which not possible. guarantee liveness, i.e., clients eventually receive replies (sentinel proof retrievability) algorithm traditional por that detects data verifiability setting their requests, provided most replicas are faulty and specific file fingerprint (sentinel). file fingerprint delay(t) does not grow faster than indefinitely, i.e. add control over the time design. block random values and indistinguishable from encrypted data. the spor protocol structure includes the following three parts: since pbft itself has limit the total number nodes the public communication, the idea asynchronous bft time control and node control, which provides design idea the design asynchronous bft compatibility genaro. that say, related measurement and control the number node synchronizations and the time sampling required. being randomly constructed check values. let denote the file with its embedded sentinels. and efficient way verify the integrity the file storage and the relevant proof that can fully retrieved. genaro chose representative spor algorithm [], which provides complete, provable, and secure theoretical system for file storage integrity verification. can use this set storage integrity verification algorithms provide important auxiliary information for the genaro chain style consensus algorithm introduced later, achieve organic and asks the archive return the corresponding sentinel values. genaro's ultimate goal have public chain that can encrypted shared files themselves can proven have storage integrity and can retrieved. need reliable verification phase: ensure that the archive has retained specifies the positions some sentinels sentinel proof retrievability (spor) encrypted and shared. first need ensure that the setup phase: the verifier encrypts the file then embeds sentinels random positions file sentinels security: because encrypted and the sentinels are randomly valued, the archive cannot feasibly distinguish priori between sentinels and portions the original file. thus achieve the following property: the archive deletes modifies substantial will with high probability also change roughly substantial sentinels. provided that the verifier requests and verifies enough sentinels,it can detect whether the archive has erased altered substantial fraction page genaro network yellow paper suppose that the file comprises blocks: ,...,f the stored function entailes four steps: around error correction: carve our file into k-block consider chunks. each chunk apply (n,k,d) -error correcting code which expands each chunk into blocks and therefore yields file ,...,f ,,, the total file expansion i.e., adversary that has corrupted the data blocks and unused sentinels calorie feet,h and )/( now upper bound the mean number with =bn blocks. corrupted blocks per chunk). theorem [], yielding file our protocols require the ability the file unretrievable. decrypt data blocks isolation, our aim recover even when the archive deletes corrupts suppose that let blocks. thus require that the cipher operate sentinels with each challenge. since the total number independently plaintext blocks. sentinels encryption: apply symmetric-key cipher sentinel creation: let suitable one-way function, compute set sentinels k,o append these sentinels yielding permutation: let ,}j ,...,b s}* pseudorandom permutation. apply permulate the blocks yielding the output file for example: block size bits the size aes block and yields sentinels sufficient size protect against brute-force sentinel-guessing attacks. let consider use the common(yu -reed-solomon let consider file with i.e., the verifier queries the verifier can make challenges over the life the file challenge per day for about three years). the probability detecting adversarial corruption the file least this not overwhelmingly large, course, but probably suffices for most purposes, detection file-corruption cumulative process. mere challenges, for instance, provides detection-failure probability less than ,,. better sampling mechanism genaro's innovation was make changes the previous spor algorithm based the characteristics the public chain. the operation the public chain, there will pseudo-random hashes. the storage process, the number fingerprints per inspection small, the miners will have relatively low cost when attacking. combining these two blocks, i.e. gbfile. ensure the validity file storage backtracking. the new version, will use better sampling mechanism instead this file expands just over under error-coding size (shwa shwa feet,h feet feet i.e. the probability that the adversary renders chunk can obtain (yu code over blocks. features, genaro designed sampling mechanism that conforms the public chain storage. the previous spor, code, means the standard technique striping consists then (shwa suppose that add sentinels.thus the total number blocks used specific file fingerprint, which the sentinel, the previous one. for details, refer []. the following, replace the sentinel with file fingerprint, and the granularity refers the size the file fingerprint. specifically: page genaro network yellow paper turned the original single file fingerprint into fingerprint set that requires time are quite random multi-selection type, that is, have finer granularity for each the previous file fingerprints, different the verification signal giving the required receipt. this case, the replay attack made, the that easier for the miners contribute the longterm contribution when selecting miners. miner needs generate groups, which means that the three verifications fail, can concluded that the miner has not contributed and discharged the miner, for example: when the file fingerprint granularity the miner can get unit file fingerprint long the difficulty for the attacker greatly increased. fact, use finer granularity than previous versions our exceeds contribution capacity. get the next need development, which can increase the difficulty. contribute plus when the granularity the miners who contributed before got fingerprints, but you want get file fingerprint, you only need increase the contribution when you have large granularity, for good miner who wants make more contributions incentive. the random number selected the specific byte the hash generated the block, which ensures that the file fingerprint each test cannot predicted. the generation random number the blockchain relatively limited. choose the partial bytes the hash generated each block evolution the basis for selects unified check multiple times each time you select selection, and the relative probability these fields file fingerprint, and perform the traceable test randomly selecting the fingerprint group. relative the relatively small. that say, miner wants something wrong particular block, they first need verification single fingerprint, the miner (that is, the stake the system and contribute specific standard and the same time just for the replay attack and the part responsible for receiving the storage the storage system) predicts the verification problem given the verification node relatively easily, thereby performing replay attack which specific fingerprint given miners who are backing with him the same time, thus the probability relatively small and requires lot cost achieve. advance delete specific file. order technically reduce the possibility replay attacks, have adopted random selection fingerprint group verification. this can improve the single check random group class, which greatly reduces the chance replay attacks, and increases the difficulty attack finer granularity. for example, the original case, miner has fingerprint no. file single verification, only needs submit the fingerprint no. file receipt the verification signal continue the replay attack without considering whether save the no. file. the only thing that can ensured that the file generated the image not attacked. otherwise, the mirror node used the same time, then the file cannot retrieved; the fingerprint set verification, the miner has fingerprints single file and once fingerprint set that requires and and compared with the previous sampling mechanism, the new file fingerprint group sampling mechanism has better characteristics for backtracking proof miners' replay attacks and has better incentive mechanism for miners than larger granularity file fingerprints. chain style pos before introduce the chained pos, worthwhile compare the other mainstream chain consensus forms. the most mainstream now the chained pow, also known the nakamoto, the most representative which are bitcoin and ethereum. the existing pow has workload the /gh class and the memory i/o class the cpu/gpu class th. the cryptonight form used monero and bytecoin was cracked asic processors, resulting more and more limited anti-asic algorithms, such blakeb. the memory configuration asics becomes page genaro network yellow paper higher and higher, the asic configuration related pows availability preserved, this case, consistency not will become more and more serious. new public chain, you continue use pow, will easily succumb guaranteed that is, the attacker can fork through the attack. moreover, terms energy consumption, the entire system cost-controlled means energy also believes that the response before the block has just been farthest block. the entire distributed system, the system consumption, which was considered unsustainable the recovered, our new approach needs guaranteed special transactions status checks. genaro uses the latter beginning the design process for genaro. based these considerations, the genaro public chain was originally here and this part will covered the storage hybrid consensus section. designed with the concept chained pos. the details the proof stake, need consider the choice the fork condition quickly eliminate the forked part quick way. that say, for pos design, need consider two pos problems: nothing stake and long range attack []. storage overlay hybrid consensus order solve the problem the above two chained pos problems, genaro has devised mixed consensus through the combination the storage part and the public chain. first all, need briefly mention the storage-related nothing stake components, i.e. the file fingerprint group. ensure the integrity the file uploaded into the distributed storage the problem the design the pos system that contrast pow's continuously increasing work costs, pos network through the random fingerprint pair and por algorithm the file, that means can retrieved nodes only need stake participate consensus. timed random sampling method. easy stake that user who can pledge lot tokens can perform multiple forks for proof, and this for example, when uploading file, the file stored situation also the most profitable option for the prover. for example, when multiple forks happen simultaneously, simultaneous authentication the forks the most profitable choice for the attacker, because matter which the longest chain, will get the benefit for the whole stable system because flp unlikely characterized adding fingerprint record, and the reliability increased redundant storage related method. then the related operation checking the storage side periodically performed, specifically, pseudo-random pattern obtained block hashing. this checks the random fingerprint pair the fingerprint group record. the return value correct, the verification will pass, and any error constant balance dual-valued states. timeout operation will not pass. mixing the previous practices into our chain, can see how solve the two mentioned earlier that there need provide stateoriented job the system. genaro's work done adding problems mentioned earlier. additional storage information, which covered the for nothing stake, provide the total number storage hybrid consensus section. inspection fingerprint record groups the blockchain consensus operation. since the total records the long range attack this attack works thanks the way reserve availability the cap theorem. what the attacker needs attack through the attributes this system. because the inspection are synchronized the chain, the multiple forks the only part the main chain that can synchronize the latest the total number fingerprint inspection records with relatively large value. this extra piece information the part the information that was page genaro network yellow paper previously mentioned push the balance the two-valued conclusions derived from successful pos cases. state. with this information, can impose additional penalties the attacker who bet the wrong fork. compared with the nodes dpos eos, greatly increased number. inclusiveness also increases the difficulty adding new node flood attacks; for the long term attack, with the previous solution, since the fingerprint verification record introduced, the part each round the committee will generate block turn the relatively long block fork can determined the total number. even the fork can evolved the beginning, and the higher ranked nodes will have more rounds. the existing block generation divided into round out after the verification point, will stop because the total number fingerprints smaller than the main fork. block and random number block. ouroboros, the random number encrypted and communicated, the after solving these two related problems, new problem block output occurs according specific random number, because has been determined that the pos arises. long range attack starts from the previous not necessarily comprised good nodes. genaro finds fingerprint verification point, new attack mode mayarise depending how quickly the attack repelled. genaro good nodes and then ranks them storing additional information about how data can retrieved. with will introduce the governance the consensus and solve the problem through chain governance. genaro's approach, can generate blocks faster because you save the random number communication operation; data governance design indispensable link the consensus, the governance structure also makes major difference from the traditionally structured internet. network statisfying consistency, verification the system can proven within the specified time, then the network statisfying availability, each node the system needs follow specific data governance structure broadcast order maintain the fault tolerance characteristic the entire system. the data governance structure the genaro public chain, can design the following governance methods through the additional information obtained the storage network: each storage node needs stake enter the system contribution storage unit; after storage, the ranking calculated the combined hefts the storage contribution and the stake amount combination; highly ranked nodes generate block operations the public chain. the selection nodes based large nodes can choose small nodes contribute storage for themselves. under this governance structure: each storage node wants start contributing the system and needs stake enter the system. the design, the storage node needs relatively stable. this mechanism for entering the threshold for the admission mechanism can selected the primary node. part the screening has already been obtained, because when the data needs stored, the storage space needs and the space for mapping backups require relatively robust storage nodes ensure that the data can retrieved later. since the members the committee are ranked the comprehensive heft the storage contribution and the amount the stake, the nodes the chain system need recognized both the storage network and the public chain accepted the committee. that say, for single approach pledge, the ranking the storage network can stably kept the committee relative the nodes that can guarantee the page genaro network yellow paper stability the system and avoid being pushed out people with excessive assets. the large node can encourage more small nodes participate the storage construction the storage network letting the small nodes contribute storage, and the large nodes can also improve their ranking this way. such participation mechanism allows medium-sized nodes and large nodes have chance play. although there are different divisions work for large nodes, medium nodes, and small nodes, there fair part the overall mechanism design. mediumsized nodes can compete with large nodes, and small nodes can sell their own storage obtain additional blocks. summary and outlook the current technical advantages genaro network include: the design the sentinel set, the original hybrid consensus mechanism and the combination the consensus spor and the chained pos, the unique data management method the chain, the encryption algorithm which involves specific features gsiop, the storage information the instruction level the stack and the special transaction meet the storage requirements, the means which the number times the miner asked multiple times reduced, thus increasing network stability. the future, genaro will consider more encryption storage features, including the use de-duplex encryption ensure that single encrypted file not redundantly processed increase miners' benefits. encrypted file stream storage allows users download and watch streaming media operations. terms consensus, genaro will provide more fine-grained consensus improvements ensure the participation small and medium-sized nodes and increase the instruction set new vms expand and increase more application scenarios. page genaro network yellow paper references schollmeier, (). definition peer-to-peer networking for the classification peer-to-peer architectures and applications, proceedings the first international conference peer-to-peer computing, ieee. bandara, and jayasumana, (). collaborative applications over peer-to-peer systems challenges and solutions. peer-to-peer networking and applications. arxiv:.. stoica, i., morris, r., karger, d., kaashoek, and balakrishnan, (). chord: scalable peer-to-peer lookup service for internet applications. acm sigcomm computer communication review. (), rowstron, and druschel, (). pastry: scalable, decentralized object location and routing for large-scale peer-to-peer systems. ifip/acm international conference distributed systems platforms (middleware), heidelberg, germany, maymounkov, and mazieres, (). kademlia: peer-to-peer information system based the xor metric, international workshop peer-to-peer systems, juels, a., and kaliski, (). pors: proofs retrievability for large files. proceedings ccs acm press. naor, and rothblum, (). the complexity online memory checking. journal the acm (jacm), (). yu, s., wang, c., ren, and lou, (). achieving secure, scalable, and fine-grained data access control cloud computing. infocom, proceedings ieee, blaze, m., bleumer, and strauss, (). divertible protocolsand atomic proxy cryptography. advances cryptology--eurocrypt', ateniese, g., fu, k., green, and hohenberger, (). improved proxy re-encryption schemes with applications secure distributed storage. proceedings the annual network and distributed system security symposium, michael j.fischer, nancy a.lynch and michael s.paterson, impossibility distributed consensus with one faulty process, journal off association for computing machinery. lynch, and gilbert, (). brewer's conjecture and the feasibility consistent, available, partitiontolerant web services, acm sigact news, (), castro, and liskov, (). practical byzantine fault tolerance, the proceedings the third symposium operating systems design and implementation, new orleans, usa. bentov, i., gabizon, and mizrahi, (). crytocurrencies without proof work. international conference financial cryptography and data security.- maymounkov, mazieres, kademlia: peer-topeer information system based the xor metric. iptps revised papers from the first international workshop peer-to-peer systems. a.d.kshemkalyani, m.singal, distributed computing: principles, algorithms, and systems, isbn:, paperback edition, cambridge university press, march pages page