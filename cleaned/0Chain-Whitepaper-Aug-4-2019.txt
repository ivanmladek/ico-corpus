chain decentralizing storage saswata basu, tom austin, siva dirisala and chain team aug abstract there are two relevant data trends. data expected grow from (zettabytes) today years. and the cloud moving the edge for performance and availability, driven iot applications, multi-player gaming, autonomous vehicles, and content streaming. decentralization would accelerate this change and adoption, lowers deployment, management, and scale-out cost. this end, chain decentralizing storage. chain dstorage cheaper and higher performance than traditional cloud. the protocols provide layer privacy, security, transparency, and service assurance. for consumers, the benefits are privacy, anonymity, and transparency. developers have better customer data protection lower cost. enterprises can scale out their data protection lower cost. for msps, dstorage provides higher revenue potential. the dstorage platform built chainnet, permission-less, fast finality, scalable blockchain, built from scratch golang. chainnet protects its network from sybil with nonlinear proof-of-stake protocol, and prevents blockchain stalls from ddos attacks using multiple leaders. client protection accomplished using serverless protocol for individuals, and cryptographic multiple signature protocol for exchanges and businesses. chainnet offers innovative token economics which enables users and developers get "free" services, such transactions and storage. users can lock zcn tokens like bank cd, get interest tokens immediately. storage providers ("blobbers") need stake zcn tokens receive expected payment. more applications use our network, zcn will grow its intrinsic value relative the data stored the network, and tokens locked for interest, users interactively lock and stake tokens participate the ecosystem. this sense, zcn the first crypto asset tied data and interest. unlike bitcoin, ethereum, and other projects, chain inflation primarily driven token holders desire mint "interest" tokens, which are given token holders for locking staking their tokens, rather than "reward" tokens given miners only. chain has recently re-tooled its token economics provide on-going rewards support the community developers and ambassadors well. addition, chain has allocated portion team tokens fund the reward tokens for the first years after mainnet maintain low inflation. after years, the rewards will generated the network and the interest will set maintain average target inflation rate about -%. this provides benefits the entire ecosystem miners, developers, ambassadors, and token holders low inflation rate. dstorage platform the motivation behind the design the platform offer cheaper, faster, more secure and more available storage than traditional cloud. let's discuss some inherent challenges with offering such service decentralized environment. how protect against data loss? how ensure that even one some the decentralized parties are down, the overall service not effected for every single stored file object? how make certain that the decentralized parties are really storing the data for which they are getting rewarded? how avoid currency fluctuation for our managed storage provider (msp) customers? how dapps preserve data consistency among multiple parties execute their smart contracts? some challenges are inherent and relatively new the decentralized systems. below, will explore each these challenges and the approach chain dstorage has taken. this has been also discussed the ethresearch forum. several patents pending idc projection for data chain tokens tokens this white paper refer the utility entity used for compute and storage resources https://ethresear.ch/t/dstorage-better-than-traditional-cloud// data availability traditional storages offer two types solutions. one replication where each data stored multiple times and multiple locations when one disk location has fateful incident, the data recoverable from the other. this what exists today enterprises when they back their storage two separate locations, addition local copy premises. the other option store the data using erasure coding technology. erasure coding can best understood set equations required solve set variables. there are variables, one needs equations solve them. anything more either produces inconsistent result redundant. example encoding erasure coding where original data blocks through expansion into blocks. this gives safety where even with the loss any the blocks, the original blocks can recovered. chain storage uses the erasure coding technology, shown fig ensure data available, and benefits from cost savings the availability cost times the original data, instead copies, and the availability gained nines compared nines -copy replication. more this section how improves cost dynamics for enterprises and smes. fig chain storage protocol where the file split into parts and sent different storage providers (blobbers) data performance reliability erasure coding helps with data performance and reliability. with blobbers down, the original data can still restored from the remaining these are independent blobbers, their failure (hardware, network, natural disaster) probability mutually exclusive, resulting very high reliability. data can uploaded/downloaded parallel all the blobbers. this results tremendous network time savings. for example, file expands into due erasure coding, but each blobber uploaded only encoded file. so, effect, the upload time will the client uploading just file. course, the assumption here that the client has enough network bandwidth upload simultaneously different service providers. but the point is, the upload time now dependent the bandwidth the client rather than the bandwidth single server traditional storage platform. when downloading data from multiple servers chain storage, the client tries download from all the blobbers but only needs wait for the first reconstruct the data. this results fast and smooth download experience. always-on data protection data protection issue for traditional storage providers well, but different context than byzantine conditions, and more due bit rotting and issues related hardware. for this, the traditional storage systems have means self-validating and recovering. decentralized system, there way enforce the operational practices and quality each service provider just policy. this assurance needs part the protocol. just like proof stake based consensus algorithms that offer rewards well slashing stake, the service providers are rewarded and punished for passing failing challenge that ensures that the provider doing what required. chain uses smart contract driven challenges for the blobbers. the challenge itself completely random (but deterministic for given block ensure consensus). the blobber and the specific file and fragment within the file picked for challenge random manner. such randomized systems have statistical outcomes that can tuned achieve desired level quality service. ensuring high quality requires doing frequent challenges. hence the challenge protocol should light possible terms bandwidth requirements. the same time, important able validate much possible. say file stored blocks and the file size mb. challenging the entire file content stored blobber (mb after erasure coding) waste lot network bandwidth. challenging any the random blocks reduces just overhead. however, this has potential for blobber download the content, reconstruct and then serve the supposed have stored. note that chain storage offers both private and public content. the private content can only read the owner any user authorized the owner. hence, blobber will not able download the private content pass the challenge. the following attack scenario and the defense against valid only for public content although the challenge behaves exactly the same both scenarios. outsourcing attack our protocol avoids outsourcing attack ensuring that the content provided for verification but the content required create this verified content the full file fragment. this done follows. the file fragment stored with the blobber divided into fifteen blocks. each these blocks are further are divided into byte chunks (just for discussion and final chunk size will fine tuned dynamic). there are such chunks each block that can addressed using index now, imagine that the data each these indexes across the blocks treated continuous message and hashed. then these hashes serve the leaf hashes the merkle tree. the root this merkle tree used roll the file hashes further directory/volume level. the merkle proof provides the path from the leaf the file root, and from the file root the volume level. with this model, order pass the challenge for file for given index (between and dishonest blobber first needs download all the content and the chaining construct the leaf hash. this discourages them avoid storing the content and engage outsourcing attack. validators addition blobbers, the dstorage also relies special role called validators. their role validate and give verification signatures that the blobbers can collect and with enough signatures, they establish their validity the blockchain. the fact that there are multiple validators beneficial for the following reasons scales with storage growth and number blobbers the network individual validators cannot get the blobbers punished increases the reliability the network case validator downtime parallel async blockchain transactions all reads and writes have get registered the blockchain for the following reasons the payments the blobbers are happening the blockchain via the storage smart contract (hence completely decentralized) there audit trail every read and write the storage. this audit trail useful creating not only security driven applications but also monetization applications that needs indisputable proof what actions have been performed users for which the content owners need paid. because need record every read and write the blockchain first might indicate bottleneck compared traditional storage model. chain protocol designed specifically reduce this bottleneck. this done making the blockchain transactions asynchronous the actual read/write operations. this done making use read and write markers that can cryptographically verifiable. the users present these markers the service providers and get started right away and the service providers redeem these markers for rewards offline. the blockchain itself trusted, long the markers are valid, the service providers are guaranteed paid. preserve data consistency among validators for oracles and ledger constructs decentralized app (dapp) needs provide auditable transaction history and provide data consistency among multiple parties order for them execute the data the smart contract. this detailed the hyperledger forum. proxy reencryption proxy re-encryption technique where party can encrypt and save the content with party and later share the encrypted content securely with anyone providing proxy re-encryption keys. these keys are tied the public/private keys the storage the chain network:the blockchain observable storage system (boss), p.merrill, austin. https://drive.google.com/file/d/ tnjb_ovxsqqgfrfeubdmppclk/view https://lists.hyperledger.org/g/fabric/topic/does_hyperledger_have_a_way/?p=,,,,,,::recentpostdate%fsticky,,,,,, sharing encrypted files blockchain made simpler, selvi and paul, dirisala, basu, and rangan, https://eprint.iacr.org// receiving party and the re-encryption process performed the party storing the content before serving the content the receiver. dstorage usage app leveraging decentralized storage the diagram fig provides overview how app can integrate with dstorage leverage decentralized storage for hyperledger (same applicable for oracles that work with smart contracts blockchains such ethereum and eos, and other ledgers such corda, ripple, steller, iota). the use case enterprise app that collaborating with multiple parties using hyperledger wants share the documents while submitting the hyperledger transaction. however, since hyperledger not suitable for storing large amounts data like documents, the document first uploaded dstorage, and then the hash the content submitted the hyperledger transaction along with the pre keys for each endorser that needs verify the content. the endorsers then download the content from dstorage and confirm that the hash the content matches with that provided the transaction. this ensures that all the parties can trust that they have received the same document pertaining that transaction. fig off-chain storage documents for ethereum and hyperledger based enterprise transactions msp payments usd when offering decentralized storage enterprises, they may prefer pay for the services using fiat currency. similarly, service providers might want receive some their payments fiat currency while keeping the rest the native token value the blockchain. while smart contracts the blockchain can keep track rewards the native token, there standard provision allow the rewards tracked mix tokens and fiat currency. chain offers such mechanism accumulating the rewards dual units. this achieved tracking exchange rate between the native token and any fiat currency, say usd regular basis. the exchange rate itself tracked via smart contract that allows changing the rate using some type governance, for example, multi-signature voting system, there ensuring that the exchange rate used publicly verifiable and trusted. once such exchange rate available for the smart contracts, then upon computing the rewards the native token, the smart contract can split the rewards into native token amount and the rest tracked fiat currency using the currently tracked exchange rate the blockchain. the native tokens are directly transferred the service providers wallet the blockchain while the fiat currency balances are tracked separately smart contract. using this method, the actual payment using the fiat currency can happen periodically, say once month, off-chain. when the payment happens, the corresponding fiat balance needs adjusted the blockchain. the transaction that does the adjustment can provide the off-chain payment proof part the transaction payload. can the form digital image, bank check url that provides payment information party such bank payment gateway. for stable coin, the interactions will similar this construct with just the replacement fiat currency. the msp payment model depicted fig fig msp payments usd overview chain blockchain order bring fast, scalable, and secure dstorage platform, needed fast, secure, and scalable blockchain. chain's blockchain architecture described fig where have parallel processes and separation roles order achieve high speed and scalability. this end, separated the role miner into miner, sharder, blobber, and validator, they can scale independently. transactions are submitted miners, and they validate them and generate blocks, and send notarized blocks sharders, who store the block and respond queries. this way the miner not getting bombarded submissions and queries, and can achieve faster response time. the blobbers store data, and the validators challenge the blobbers. the clients interact directly with the blobbers when they upload download data. the validators interact with blobbers they validate their challenge response. the blobbers submit successful challenge response the blockchain for tokens. these off-chain processes and transactions make the storage and blockchain platform scalable and fast. fig chain consensus protocol "the chain consensus protocol", katz, austin, dirisala, basu, https://drive.google.com/file/d/kcfkqhmtgxvxzztalnkvhmmicwoiak/view multiple leaders decentralized systems need both fault and byzantine tolerant. among the proof-of-stake (pos) systems, some protocols choose consensus electing leader and change the leader regularly and also when the leader not making progress. problem with single leader based system that can prone external attacks such ddos. hence, these protocols are typically suitable for private permission networks. for public blockchain, desirable have protocol that can effectively defend against both byzantine conditions and also external factors like network outages and ddos attacks. some protocols such dfinity propose having multiple leaders that the blockchain will make progress even some them are faulty. chain adopts similar approach where more than one miner can generate block given round and while the network collectively works towards notarizing the highest ranked block given round, the goal eventually notarize and make progress with any the blocks that got generated the round and pass the verification process (transaction signature validation, replay transactions and on). order achieve consensus without leader, and mitigate the risk network attacks, consensus achieved everyone sending their verification messages every other miner the network. use the same logic dfinity regarding block weight which /^r where the rank the generator starting from so, the block weights and on. verifiers give preference the highest weighted block. terms view change, differ from dfinity. they require individual node and group enter into the blockchain after "epoch" view change. allow anyone join into the upcoming view change. and, only have single group. sybil protection chain uses non-linear proof-of-stake (nl-pos) staking approach. note that the mainnet will launched with squared power stake. the idea behind this that someone with lot tokens would prefer pool them all together have better chance participating, rather than splitting into several parts and joining the network separately. deterministic finality protocol doesn't require explicit endorsement block reach consensus and just rely other factors such pow, possible disclose blocks much later and alter the course. many pos protocols require direct interaction with each other reach consensus, using variation pbft (practical byzantine fault tolerance). immediate direct interaction ensures consensus discovered quickly and will not possible release blocks later time. this makes these protocols almost deterministic compared what possible with bitcoin for example. when multiple blocks can proposed for given round, sometimes possible not able determine block finalized because network conditions. this where protocols such hashgraph take different approach. they rely the fact that the current proposals are consistently endorsing past transactions and when majority the miners endorse directly indirectly given transaction, gets finalized. transactions get finalized individually but the same concept can applied the block level. that is, when enough miners extend directly indirectly off given block, possible agree which the notarized blocks round should finalized deterministically. chain executes finalization based locally available information but also keeps track the deterministic finality using the hashgraph like logic applied the block level. our experiments have not seen any rollbacks finality computed based local information even after running the blockchain for hundreds thousands blocks. the clients interacting with chain have several choices deciding when consider their transaction finalized. they can choose wait certain number blocks, they can choose query the confirmation from multiple nodes combination both. chain, there are three blocks that are interest. they are: the block that being added the current round the block that probabilistically finalized using variant dfinity algorithm the block that deterministically finalized using logic explained below. should noted that the deterministic finalized block lags the probabilistic finalized block which lags the current round block (if all miners generate, then possible have deterministic finality fast probabilistic finality). when miner receives block for round and from valid generator for that round, added the local cache blocks. during that time, the chain from that block walked back till the previously identified latest deterministic finalized block. for each block between, added unique extensions map the block the miner the current block hasn't extended any block between this intermediate and current block. after sufficient progress the chain, some point each block that probabilistically finalized will receive enough number unique extensions, indicating that sufficient number miners are working top that block. that point, the block becomes deterministically finalized. the threshold used for deterministic finality will the same the threshold used for notarization block. for example, for *f+ miners with number byzantine miners, there should more than /rd unique block extensions for block considered finalized deterministically. the diagram fig indicates the above explained process. the letters the block indicate the miner who generated the block. the letters the green boxes below represent the unique chain extension endorsements for those blocks. also shown are additional block proposals and received particular round. let's assume that receiving unique extensions considered the threshold. soon block from received the current round, the block becomes finalized deterministically gives extra unique endorsement. similarly, when block from received for current round, the block becomes deterministically finalized. the deterministic finality moves from and so, having more generators help accelerate deterministic finality, albeit with increase network traffic. fig deterministic finality sharder workload optimization mentioned earlier, our miner-sharder architecture, recognize that the mining process cpu intensive while responding queries finalized transactions storage and network intensive workload. the sharding blocks further optimized among sharders using consistent hashing like algorithm and splitting the blocks among the sharders. that is, the chain blockchains can configured choose the number replicators per block and only those many (and sometimes few more) sharders store the block. which set sharders are replicating given block completely deterministic from the hash the block. while blocks are sharded, the mapping information regarding which transaction has made into which block stored all the sharders. this way, client can initiate query with any sharder and the best case scenario that sharder has the block information and will respond back with the entire transaction information and the worst case scenario, will only able tell which block the transaction belongs the client can query the details from the right sharder. governance while blockchain decentralized and the core operations validating transactions and producing the blocks all automated and achieved via consensus, many blockchains have little overarching governance that helps through any unforeseen issues such malicious attacks faulty code requiring major changes and on. chain has taken decentralized stake based governance approach. that is, any changes required the blockchain will approved vetoed via staked voting mechanism which itself done smart contract the blockchain. addition, avoid last minute manipulation, chain uses novel multi-round exponentially increased limit mechanism complete the voting process there making robust, fair and transparent possible. learn more, check out here. fast sync merkle patricia trie since chain has fast finality the state rapidly changing. so, becomes critical able sync the state fast and operational, even with partial state contribute the overall consensus. ping-pong governance: token locking for enabling blockchain self-governance, merrill, austin, rietz, pearce. https://drive.google.com/file/d/ziadhrekbyx_hjxmcznubm_c-pgm/view posted ethresearch: https://ethresear.ch/t/fast-state-management-using-merkle-patricia-trie/ state management integral part the fast finality claim together with the execution time smart contract. the production block involves executing smart contract logic associated with the transactions the block that result mutating the underlying dlt state that securely verifiable. so, when comparing blockchains and their finality claims, it's important keep this full picture mind, and not isolation being able fast byzantine consensus. sync expensive today most blockchains using mpt, when new node comes online, for participate the blockchain process generating validating block, first needs sync the entire mpt. the mpt can very large data structure depending the number keys present running into several millions. the blockchain popular, such ethereum, can easily into billions over time. this makes very time consuming sync the entire tree. one the key observations transactions blockchains is, like many other things, the rule. that is, the blockchain used users and smart contracts (there good chance that these numbers are even more skewed). hence, doesn't make sense for someone wait loading the entire state represented mpt synching data related long and growing tail users and smart contracts that hardly transact and the process impact the quality service for the rest the users. ideally, it's possible make progress with partial state that helps the nodes start earning rewards soon possible. but possible support this given that the mpt updates are expected securely verifiable with each block produced the blockchain? the answer, not surprisingly, turns out yes. the mathematical properties the mpt provides solution with proof correctness. fast sync mpt (fs-mpt) let's first define some terminology. application using mpt has api store value with given key, represented (k,v) and storing several such values can represented (k,v) (the upper case just defines set while the lower case represents single element). order provide security proof, mpt has store some intermediate nodes addition and hence collectively represented (n). further, the application keys (k) end representing the paths the mpt access the values, while hashes the nodes, are used keys the nodes. hence, mpt mapping (k,v) (h,n). the (h,n) pairs are persisted into key, value store (such rocksdb used chain). note that the pair (h,n) self validating because hash(n). say given blockchain round, the mpt represented (hx, nx). subsequently the mpt got modified the blockchain progressed. for given block, let's say the state got updated (inserted/deleted) small set keys and values, (kb, vb). the new mpt after applying the changes (kb, vb), contains subset (hx ,nx) intact and new set hashes and nodes (dhb, dnb) together representing the new state, (hxb, nxb). the key observation here is, order compute and verify the new state, any partial state (hxp, nxp) which subset (hx, nx) sufficient long possible compute (dhb, dnb) using this partial state. when the new state computed from the partial state, the root hash will agreement with that computed with the entire state. this very important and coupled with the commutative property, possible keep operating the partial states while simultaneously synching the missing state, (hm, nm), block block ad-hoc and applying (as just storing the new hash, node pairs) the existing state. the order which these delta changes are applied doesn't matter. chain blockchain uses the above concept support the ability make progress with the blockchain (to generate block, validate block, respond client queries for balances, other state related queries). while good able make progress, eventually the entire state needs synched which can happen parallel. the state sync itself happens via two separate partial sync strategies mentioned below. block level partial state sync that is, applying transactions block initial state mentioned above results (dhb, dnb) delta state changes. this delta change includes the root key and node and since the root the state mpt part the block hash, possible verify that given delta state matches with given block. result, when node making progress with the blockchain and temporarily unable validate the state block, can request for the block specific partial state, validate that his partial state correct and start using it. this helps with any temporary downtime such short network outage and allows updating the partial state full state without having replay the transactions all the intermediate blocks compute the state. this makes the temporary state sync process very fast. missing state sync mentioned, mpt versioned data structure default and hence accumulates lot (h, tuples. these need pruned contain the size the state db. chain has state pruning logic that similar garbage collection mark and sweep logic. during this process, possible identify the set missing state (hm, nm). when missing state detected during the "marking" process, will sync that state (randomly asking peers for related set hashes, hm) and abandon the "sweeping". this can continue several times discovering some missing nodes can lead discovering additional missing nodes that are children the original missing nodes. eventually when the entire state synced, the older state that longer required pruned. note that the "marking" process traverses the tree while the "sweeping" process just traverses the underlying database. result the "marking" process can expensive and chain has configuration specify the frequency which this process runs. however, when the state missing, this configuration ignored ensure the state synched fast possible without waiting for the next pruning cycle. likely that the "marking" process can further optimized storing the nodes each level separate database column family reduce random i/o, something that can explored the future. mpt used for each smart contract maintain its own state and the root hashes each these are stored values the global state that maintains state the client wallets and smart contracts. this similar how ethereum manages it's state. each mpt can independently synched and will possible prioritize synching some smart contract states over the other based popularity for example. the fs-mpt approach state pruning and synching provides chain with robust state management. the ability sync partial state changes block block provides the benefit synching state faster for frequent users and smart contracts (and hence get ready support them with their subsequent transactions), while eventually syncing the entire state discovering the missing state the background. this improves the stability and quality service the blockchain. efficient dkg using blockchain chain blockchain relies publicly verifiable random value calculated with each round block generation. this achieved using dkg (distributed key generation) that provides the ability recover group signature using t-of-n threshold signature scheme. that is, order defend against byzantine and other faults, only threshold number signatures are required reconstruct the group signature that everyone can verify and agree on. the group signature used seed create random number for each round and the signature for given round based the random number from the previous round. for implementation, use herumi's library for dkg which based curves. the literature has various versions dkg and the version that chain uses called joint-feldman pedersen. this protocol starts with parties but eventually ends with parties, referred "qualified" parties. the qualification happens due the nature distributed key generation that can result byzantine condition. the protocol suggests using complaints and revealing individual secret shares narrow down the qualified set parties which are all verified have shared the secrets correctly. the protocol requires broadcasting some messages the entire network and hence the messages are the order o(n) and some messages are sent only individual parties and this done everyone resulting order o(n^). these secret shares that are o(n^) where the complaints and revealing happens and that can result lot messages back and forth and also timing those messages and reliability coordinating them across all the parties. chain uses novel approach, using the blockchain itself, solve this problem. all the publicly available information submitted transactions the blockchain and each the parties need initially submit one transaction each the blockchain with the public information the protocol. after this, the parties will privately send the party specific information among themselves, that are the order o(n^). however, there complaint revealing. instead, each party part distributing its secret shares the others will collect digital signature acknowledgement that they have received and verified their secret share against the public information already available the blockchain. the end distributing the secrets all the parties, each party ends with digital signature verifying valid distribution digital signature because the receiving party didn't not provide one (byzantine) was not responsive (temporary network failure). after some amount trying distribute the shares, eventually each party will public another transaction the blockchain with array digital signatures confirming the receiving valid secret shares the secret share value and the corresponding party that didn't provide receive the secret share. that is, the onus each party submit this information the blockchain without which the party automatically disqualified and hence each party has the incentive submit this transaction. any party that not able gather least confirmation signatures will automatically gets disqualified. for anyone who only didn't receive fewer than the threshold confirmations, the corresponding secret shares are revealed but they can't used reconstruct the secret information that party (as least threshold number secret shares are required reconstruct the private information). the revealed secret share values can used honest parties that genuinely didn't receive the secret shares all were given incorrect values they are now publicly available the blockchain and verifiable. using the above logic, the qual set can deterministically computed each party using the publicly verifiable information available the blockchain. hence, this eliminates some the complexities identifying the qualified set with the original dkg protocol that only suggests exchanging complaints and revealing/reconstruction messages which can large and time consuming. contrast, the blockchain only requires o(n) messages that are all available the blockchain and further the onus disclosing with each party that want get in. efficient secure light client validation decentralized blockchain, the set active miners and sharders constantly changing. hence, any client using blockchain needs either interact with centralized server submit and query transactions effectively making part the solution centralized, need cope with dynamic decentralized system. chain provides mechanism discover these active miners using concept similar domain name lookup service, dns. the change the active set referred "view change". whenever there view change, the miners and sharders can broadcast this information set external servers that single entity controls. since the view change recorded the blockchain, the external servers can query and verify the authenticity the changes. hence, clients can query and get the latest active miners and sharders from any this static (or less frequently changing) set decentralized servers. another problem for the clients dealing with decentralized blockchain confirming transaction. transaction may get finalized but sharder may respond otherwise knowingly unknowingly. they can also respond that transaction confirmed when actually not. further, since finalization lags behind, and rare cases individual sharders may falsely finalize their local view, even secure proof presented, the transaction may not have been confirmed since the finalized block may roll back. deal with all these complexities, simple approach shown fig always query sufficient number sharders for transaction confirmation. that wastes lot resources both the client and the sharders. alternatively, client can try query single sharder for long possible and only fall back multiple sharders when necessary. for example, once transaction expired and confirmation still not received, then the client can fall back asking multiple sharders for the extra confirmation. similarly, after establishing confirmation from sharder, the client can establish the validity the subsequent block chain querying different sharder for each block and necessary walking and down the chain establish trust. this ensures, one hand, the client getting extra validation confirmation the blockchain being built top the corresponding block and the other from different sharders for each block. this combination traversing the chain with confirmation from different sharder increases the trust the outcome. fig efficient light client validation client security chain worked with security researchers and came with novel solution based security protocol that has survived more than decade research that analyze vulnerabilities the protocols. this protocol, called bls, provides the ability split key into two and store them separately and reconstruct the signature from partial signatures. more details can found the "splitting and aggregating signatures cryptocurrency protocols", selvi, paul, rangan, dirisala, and basu, https://drive.google.com/file/d/ urvaaewdtonjiknklcqzgeyepl/view previously written technical article. the solution completely based software, there need for purchasing any expensive hardware. users can use their existing mobile phones and computers. chain enhances the overall security with various types wallets and stake pooling mechanisms which are additional protocol layers top the above mentioned bls signature scheme. these details are described below. end user wallets chain providing beautifully designed native mobile apps for wallet transactions and store value. the wallet app will allow user setup the keys with without splitting. use key splitting, users will also need download desktop app act second device. very intuitive will guide the user setup the split key between the two devices. once setup, subsequent transaction submission will require both devices construct the signature making secure. even with split key, will possible recover the primary key, should the need arise, just like the traditional keys. addition, will also possible split the keys any number times implement advanced security options such key rotation where set keys are periodically discarded. these advanced features are optional and casual users don't have worry about these features initially but they become more familiar with using the blockchain and the secure wallet, and their token store value increases, they can assured that such advanced options are possible using the signature scheme used chain. service provider operation wallets all the service providers the chain blockchain, such the miners, sharders and validators will need digitally sign their messages for the rest the blockchain network assured that the message coming from whom supposed and not tampered. the signature scheme used for this same that used for the end user wallets. split key functionality for additional security cannot used the service providers for the following reasons there user interaction for supporting the operations the blockchain with fast finality, the number messages exchanged per second large that would impractical add any extra steps that delay the signing process. result the above operational constraints, chain has decided provide additional security for the service providers different manner. this done separating the keys used for staking and reward from the keys sign the out going messages for supporting the blockchain operations. with this mechanism, the tokens are always controlled regular wallet that can use the split key scheme assuring that their stake never compromised. this technique will also allow the ability rotate operational keys, something that common traditional systems having advanced security. delegation pool the above separation wallets further generalized support the concept delegation which allows normal users earn rewards staking their tokens but without actually owning the blockchain operations service provider. service provider starts delegation pool registering operational wallet and staking tokens using the regular wallet and delegating the operations the operational wallet. similarly, any regular user can choose invest into this delegation pool increase the overall stake the service provider which further enhances the chance the service provider getting picked. the delegation pools are implemented smart contract and hence the owner the delegation pool cannot withdraw tokens deposited others avoid paying the rewards the rewards are automatically distributed the participants the smart contract. the reward distribution will proportional the stake each participant. multi-sig wallet there reason split the key into only two parts. can extended split into parts and even use threshold cryptography where only t-of-n signatures are required. most existing multi-sig schemes rely signing with unrelated keys establish multi-sig. while this possible, chain's signature scheme allows creating aggregate signature that can recover the signature regular client the blockchain. this ensures that the balance transfers are done securely with the use verifiable signature client via multi-sig directly signed the client. this type multi-sig validation suitable for server side wallets such digital exchanges where the transfer transactions are driven automation. developer rewards order incentivize adoption dstorage, the team setting aside tokens incentivize developers build apps, interfaces, and use chain dstorage. addition, there will tokens generated the network that will into pool for developers continue improvement. developers can disrupt existing saas and consumer applications with dstorage for better performance and security lower cost. have ongoing hackathon for useful projects that solves real world problems, and there are prizes ranging from tokens, and prizes tokens for the overall winner. see https://chain.net/page-hackathon.html for more details. https://chain.net/page-hackathon.html here are the following examples useful project categories. interface dstorage for different blockchains such hyperledger and ethereum sdk versions different languages and different platforms. interfaces for multi-party solutions, where smart contracts make use outside data oracles, and need prove that the same document shared with all the validators involved and hence not tampered any way. storage apps build new dapps using dstorage for different applications such wetransfer, pixieset, docusign, etc. social apps build new dapps that use dstorage and compete privacy with youtube, snapchat, instagram, whatsapp, netflix, and spotify. enterprise apps build new dapps that use dstorage for healthcare, real-estate, banking, government, and e-commerce store sensitive customer data and use them for multi-party transactions. secondary backup interfaces and plug-ins dstorage for veem, commvault, rubrik, cohesity, and nutanix. relevant links for development are: github: https://github.com/chain/gosdk zwallet: https://github.com/chain/zwalletcli zbox: https://github.com/chain/zboxcli community developed: sdk: https://johansten.keybase.pub web test for zwallet, zbox: http://zcn.sculptex.co.uk/zbox.php?action=info ambassador rewards the chain ambassador program exists create official role for technical and business evangelists that have expertise the chain protocols and related products such dstorage, box, wallet, who are interested helping new community members get involved the project, and develop businesses around the chain protocols. there pool tokens set aside the team (discussed the token economics section) which, future, will generated the network will fund these technical and business evangelists perpetually. you are interested connecting with ambassador your region, find out more about the ambassador program, reach out director ecosystem, derick fiebiger operations@chain.net. there are several use cases that need promoted via hackathon events outlined the developer rewards section. the idea create reward pool for ambassadors organize local events, educate entrepreneurs about these new use cases, and help develop businesses. miner rewards the miners have incentive mine our network, because they have additional sources revenue. they can still earn tokens based traditional mining and transaction fees, but can earn tokens other ways: storing blocks sharder, providing storage service blobber, "free" zcn immediately when you stake, and delegation fees when miners stake their tokens, the network generates interest tokens for them. they earn miner and sharder, and storage grows the network, they will earn more storage provider. the infrastructure requirements for miner, sharder, blobber simple server that people can either buy locally put together themselves. the parts are listed fig for storage server starter set which can mine and shard well. you already have spare parts that you can put together, then your cost nil except when scaling storage they get consumed. earn miner and sharder the earnings potential for scalable platform for miner and sharder, you were stake zcn example, shown fig the earnings are twice many you were just lock your tokens, and three times more you are able participate miner and sharder. the math simple. reward tokens per miner/sharder (tokens for miners and sharders) (number miners and sharders) the number tokens .m, and there are total miners and sharders, then you will earn about zcn each. since the number tokens have been increased for the first year with team tokens, each participant will earn zcn each. miner reward document. https://drive.google.com/file/d/ymuaqmuwbditesokkczhqctlxbg/view fig miner rig template fig miner and sharder rewards potential the rewards miners and sharders are based the following protocol. staking results payments interest the rate changes based the rate each given view change. reward are striving keep this same for miners and sharders. will have equation below that can used either keep same change the sharder stake multiple miners. transaction fee this very dynamic with each transaction and block, will hard predict this component. so, will likely just indicate this extra potential without giving any value. below the formula compute regarding the reward per round which can then extrapolated show the amount for rounds. each view change happens after rounds, then that can used the metric and project the returns per view change. even there net change miners/sharders, will the view change protocol are assuming certain payments happen with each view change. equation for reward per round per party: let the number active miners and sharders let the reward per miner per round let the reward per sharder per round multiple, the miner's reward. so, the reward k*x. let the available reward per round after rounds, the total reward given out the network the total reward received all the miners and sharders (x*m k*x*s) equating both sides, k*s). note that the above reward structure has indication number generators replication factor. but starting out, number generators replication factor and can tweak these parameters based the ongoing cost through governance protocol. cost analysis the mining network will effective only when the rewards exceed the costs. for the below discussion will ignore the interest and transaction fee based rewards for simplicity without loss generality. let the cost generating block and the number generators let the cost verifying block cv. let the number blocks verified average round let the cost storing block and the number replicators let the cost supporting queries related transaction confirmations and block for given round (this cost that has specific bound). the cost operating rounds (m-)*v*cv this reward should greater than the cost, (m-)*v*cv this implies that (m-)*v*cv r*cs the above formula indicates, the reward per block should more than the cost that does consider the number generators and sharders. so, while the reward per party does not directly have these parameters, the reward given indirectly has lower bound based these blockchain parameters. earn blobber msp (managed service/storage provider) while the earnings potential miner limited because the finite reward pool, the earnings potential storage provider unlimited. addition, the earnings can fiat currency detailed section and so, encourage miners start with infrastructure that has the potential provide them multiple streams revenue, and add-on alternatives. fig shows the earnings potential blobber the storage demand grows over the years with unlimited potential, there barrier entry. storage profit (usd) investment (usd) fig blobber earnings potential chain building msp program and community that the entire smb/sme market can served with dstorage their community. compelling cost/performance alternative traditional cloud. today, most smb/smes use dropbox, box, onedrive, aws, azure, and google. the msps can continue make the same margin selling dstorage and box smb/ smes, but can now have multiple streams revenue blobber, well miner and sharder. the msps will set their configuration portion storage for their rigs, and select other msps from the blobber pool. example, they decide erasure coding, they can send data their three rigs, the other seven msps they trust and have relationships with, and the rest anyone globally. the msp orchestration and configuration process will make this setup simple and clickable process, and dashboard will show msps how much revenue they are earning managing their customer's storage, and how much they are making their equipment. fig shows how msps have unlimited earning potential with the growth dstorage. have following payment protocol for the blobbers and clients. allocation user asks for storage allocation certain capacity offering range min and max cost per unit storage/unit time. the smart contract identifies all the blobbers who are offering storage within the cost range provided the user and randomly picks the required number for the chosen erasure coding. this ensures that the blobbers are randomly selected but the same time the cost the overall storage within the range desired the user. governance can dictate absolute min and max for these ranges desired. starvation attack when allocation created, establishes write and challenge pools which striped the client-blobber relationship. minimum the cost needs immediately paid the client for successful allocation the storage. the end the storage subscription time the client hasn't actually spent the storage, the initial paid amount ensures that the blobber paid least this prevents starvation attack the clients. the initial tokens are placed into write pool. writes happen, these get moved into the corresponding challenge pool. storage additional content, user needs keep funding the write pools. staking pool when the allocation created, the blobbers stake the storage cost for which they receive interest but the locked stake will punished they fail proof storage challenges. amount per unit storage unit time both the storage cost and the stake are converted into unit amounts the size and time. this helps interpolate the rewards/ punishment storage size and time left before expiration. for example, the stake from blobber for and days becomes stake/^ unit price per gb/ per day (the actual units used subject change based the final implementation the smart contract). similarly, the reward stored content reward size duration where reward the unit price storing the content for given blobber. storage reward set aside for challenges when user writes new file and the blobber redeems the write markers, the funds move from the write pool the challenge pool. similarly, when user deletes some files, the funds may move from the challenge pool back the write pool. however, this done only after adjusting for some reward towards the deleted content that was stored that point. this done adjusting the challenge pool assuming virtual challenge that has successfully happened and rewarding appropriately. challenge rewards and slashing blobber passes challenge time and the next challenge time with eventual expiration tstop, the amount paid will challengepool (t-t)/(tstop-t) which linear interpolation fraction the challenge pool reward set aside for the entire duration from the expiration time paid proportion the delta time (t-t). similarly, blobber passes challenge time and fails challenge time then they would penalized stake (tt)/(tstop-t). these equations, the unit price storage size does not come into picture. any challenge failure assumed failure for the entire allocation. so, while costs are calculated based the content size and set-aside for challenges, the reward/punishment challenges are purely time based. expiration the time expiration, the blobber hasn't received the original storage cost, the write and challenge pools guarantee that the blobber paid from the already locked tokens the beginning the storage allocation. beyond that, any unused amount the write pool goes back the user and any amount the challenge pool goes back the blobber. extension users can extend their storage any time before the expiration. when they extend the storage, the unit prices get readjusted weighted average the time left and the original cost with the new duration and the new prices. the cost extension determined the current cost storage and computing the cost from the original expiration time the new expiration time. however, the rewards and punishments are based the weighted average the remaining values and the new values along with the time remaining the new expiration. enterprise benefits enterprises benefit from dstorage three ways: lower cost and easier scale out their storage needs higher performance speed) and availability nines) their workload they retool their client data breach protection through auditability public blockchain supplement their budget lending out their storage the blobber pool likes the msps, envision that enterprises will form community that will actively participate form consortium storage providers among each other benefit from lower cost, higher performance storage solution. gtm strategy the msps market size the u.s. and about three times that much globally the msps serve the smb/sme market and according world bank group study suggests there are between million micro, small and medium enterprises (msmes) emerging markets: million are formal smes; million are formal micro enterprises; and million are informal enterprises (small and medium enterprises (smes)), and they all have need for protecting their data. our gtm model target msps, vars (value added resellers), and vads (value added distributors) and start serving the smb/sme community with box and dstorage, and displace traditional alternatives such dropbox and aws. will also pursue select relationships with enterprises build the enterprise community model. zcn valuation the notion that zcn, cryptocurrency, tied data and locked tokens very novel concept. zcn data asset for blobbers participate the network, they need stake the sell price their storage. for example, they are selling storage $./gb for year, and they are putting out their rig capacity, then they need stake equivalent number tokens the network. similarly, client that will use storage for year will lock much, and that amount will get paid blobbers over the year. and the average equivalent value locked/staked tokens the network for both parties average. and this constitutes the base value the network because such demand. fig shows the current data, cloud market, and penetration level expected for dstorage, and the corresponding value data stored the network. the upshot that achieve penetration today's cloud market, then there would billion value directly based the data our network. chain storage estimate (usd billions) penetration zcn equivalent stak ed/locked (usd, llions) fig dollar value data stored chain based estimated penetration zcn blockchain are familiar with bank cds, where you lock portion money for specific time period, you receive interest. the banks then take your money and re-lend higher interest rate businesses and home owners, thereby making profit. our network somewhat similar the user getting the "interest" tokens, but the other mechanics are quite different. when you lock your tokens the network, generates these tokens, similar bitcoin ethereum, but the latter coins give all their minted tokens the miners. our network, the mined tokens primarily the token holders, who desire "hodl", lock, and earn interest. the inflation our economy primarily driven the desire token holders lock tokens. https://www.channelee.com/faq/msp-market-size-forecast/ the equilibrium price chain token, andrea buraschi and sebastiaan vervest, imperial college london. https://drive.google.com/file/d/emqktzsyzxhmhmcrrsujfovhffbc/view the value the zcn network directly related the number people who will use zcn currency and receive interest tokens. the more people have our network lock tokens for long term, the higher the value zcn based the closed form supply/demand equilibrium equations the paper professor buraschi imperial college, london. receive immediate interest unlike banks, when you lock tokens, you receive interest tokens immediately. this helps hodlers use interest tokens for services such storage, transactions, and future services the chain platform. zcn valuation interest data the valuation zcn combination data the network and hodlers' desire earn interest through locked tokens. the locked and staked tokens can visualized transparently the network estimate the base value the network any given point time. unlike other cryptocurrency, the value zcn can deterministic and less speculative, and unlike most stable coins, will transparent currency. token economics the distribution tokens (by the chain foundation) outlined fig there total tokens pre-mined. the distribution follows: for the team, "reward" tokens set aside the team for miners, sharders, community (developers, ambassadors, msps) build the dstorage ecosystem for the first years after main net launched, for seed, for private pre-sale investors, reserved for team with equal vesting jan and jan the market value greater than most the team tokens will locked for several years preserve the integrity the network shown the table fig the network will generate the reward tokens after years continue funding the participants the network. the reward and interest tokens are expected constitute average inflation rate for the network. the table fig elucidates potential tokens circulation, inflation, and interest rate, and also shows the reserve token schedule. there are couple interesting observations. fig token distribution and inflation economics zcn inflation driven interest demand from token holders unlike bitcoin and ethereum, where all the minted network tokens toward the miners, the inflation zcn driven how many the token holders desire lock their tokens. and this independent storage demand. this concept depicted fig storage demand counters selling pressure and provides liquidity because the zcn needs staked the network, expect constant liquidity new storage gets signed the network. also expect the storage demand stabilize selling pressure there constant buying and locking the network. the value zcn based the number users lock tokens for interest, and amount data stored the network. zcn inflation tokens token holders, miners/sharders, developers/ambassadors old token economics: all inflation tokens miners bitcoin, ethereum, litecoin, bitcoin cash, etc. miners/sharders developers/ambassadors token holders bitcoin (old coin) zcn inflation economics expected inflation rate zcn zcn inflation tokens expected inflation rate (percentage) expected inflation rate (percentage) based tokens circul ation total circulati total tokens (locked circulation) fig expected zcn inflation products box, private cloud box private cloud. logins and emails are needed, especially the user pays the premium version with zcn tokens. the first version box, launched with mainnet, will have the fiat feature that the regular user will have user experience dropbox box, and can purchase the privacy cloud service with their credit card. this scenario, box will handle all protocols and payments behalf the user, but the user has absolute control and access their data. they can see challenges their data regularly, giving them the satisfaction that the data stored safely and not breached anyone, and they can see which blobbers are storing the pieces their data and their url shown fig addition, the consumer will have faster user experience than other competitors such dropbox. currently, box beta; check out at: https://testflight.apple.com/ join/akvfqgz wallet, serverless wallet for zcn wallet protects zcn asset with innovative serverless using mobile and laptop. either device gets compromised, your assets are still safe. the setup simple shown fig the user downloads authenticator app the laptop and uses accept transaction initiated the phone. point and click operation have the mobile device talk the computer long they are the same network. one the devices compromised your asset still safe, and you can regenerate new set keys with your original passphrase (private key). check out the ios app the app store and android app the play store. download the windows and mac authenticator from our website https://chain.net/page-wallet.html. fig box, private cloud private, anonymous, transparent fig the setup process for wallet, serverless wallet for zcn roadmap the current development has been ongoing since july the design several protocols and products. the table below shows the development and product release roadmap for leading the launch main net, following which expect work other aspects the dstorage. and beyond alpha network release sdk release betanet mainnet box with zcn ios android chainnet consensus sdk and sdk hackathon box android windows sync chainnet storage protocol cli for storage bugathon dstorage(tm) for msps, smes chainnet explorer cli for wallet launch box ios mac sync interface launch wallet ios android with mac/windows authenticator msp orchestration