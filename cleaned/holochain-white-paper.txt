holochain scalable agent-centric distributed computing draft(alpha eric harris-braun, nicolas luck, arthur brock ceptr, llc abstract present scalable, agent-centric distributed computing platform. use formalism characterize distributed systems, show how applies some existing distributed systems, and demonstrate the benefits shifting from data-centric agent-centric model. present detailed formal specification the holochain system, along with analysis its systemic integrity, capacity for evolution, total system computational complexity, implications for use-cases, and current implementation status. approach data-centric because its focus creating single shared data reality among all nodes. introduction claim that this fundamental original stance results directly the most significant limitation the blockchain: scalability. this limitation widely known and many solutions have been offered holochain offers way forward directly addressing the root datacentric assumptions the blockchain approach. distributed computing platforms have achieved new level viability with the advent two foundational cryptographic tools: secure hashing algorithms, and public-key encryption. these have provided solutions key problems distributed computing: verifiable, tamper-proof data for sharing state across nodes the distributed system and confirmation data provenance via digital signature algorithms. the former achieved hash-chains, where monotonic data-stores are rendered intrinsically tamper-proof (and thus confidently sharable across nodes) including hashes previous entries subsequent entries. the latter achieved combining cryptographic encryption hashes data and using the public keys themselves the addresses agents, thus allowing other agents the system mathematically verify the data's source. though hash-chains help solve the problem independently acting agents reliably sharing state, see two very different approaches their use which have deep systemic consequences. these approaches are demonstrated two today's canonical distributed systems: ii. this paper builds largely recent work cryptographic distributed systems and distributed hash tables and multi-agent systems. ethereum: wood [eip-], dht: [kademlia] benet [ipfs] todo: discussion and more references here git git, all nodes can update their hash-chains they see fit. the degree overlapping shared state chain entries (known commit objects) across all nodes not managed git but rather explicitly action the agent making pull requests and doing merges. call this approach agentcentric because its focus allowing nodes share independently evolving data realities. iii. https://git-scm.com/about https://bitcoin.org/bitcoin.pdf distributed systems formalism define simple generalized model distributed system using hash-chains follows: let the set elements participating the system. call the elements nodes agents. let each node consist set with elements call the elements the state node for the purposes this paper assume {xi with being hash-chain and set non-hash chain data elements. bitcoin bitcoin (and blockchain general), the "problem" understood that figuring out how choose one block transactions among the many variants being experienced the mining nodes (as they collect transactions from clients different orders), and committing that single variant the single globally shared chain. call this prior work let cryptographically secure hash function. add various sources more footnotes here call set nodes for which any the functions and have the properties being both reliably known and also known identical for that set nodes: trusted nodes with respect the functions known. let there state transition function: (si (tx (xi t), (di t)) (.) where: (a) (xi xi+ where xi+ {xi+ xi+ call channel with the property that messages transit can trusted arrive exactly sent: secure. (.) call channel which the address node h(pkn where pkn the public key the node and which all messages include digital signature the message signed sender: authenticated with xi+ {h, {h(t), {h(xj )|j let fsys the set {syscommit sysget where: functions (a) syscommit (e) uses the system validation function (e, add and successful calls dhtput (h(e), e). (f) let parameter dhthc set dependent the characteristics deemed beneficial for maintaining multiple copies entries the dht for the given application. call the resilience factor (g) allow that each node can maintain set {mn metrics about other nodes, where each contains both node's direct experience with respect that metric, well the experience other nodes enforce that one such metric kept uptime which keeps track the percentage time node experienced available. call the process nodes sharing these metrics gossip and refer for details. (h) enforce that each node maintains set closest nodes seen from which are expected also hold resiliency maintained taking into account node uptimes and choosing the value that: uptime(ni whith uptime(n) (.) (b) sysget (k) dhtget (k). (c) see additional system functions defined allow the functions fapp defined the dna call the functions fsys let arbitrary message. include fsys the function syssend (ato which when called nfrom will trigger the function appreceive (afrom the dna the node nto call this mechanism node-to-node messaging allow that the definition entries dna can mark entry types private. enforce that entry such type then note however that entries such type can sent node-to-node messages. let the system processing function (i) set functions fapp registered the system callbacks based various criteria, e.g. notification rejected puts the dht, passage time, etc. systemic integrity through validation the appeal the data-centric approach distributed computing comes from the fact that you can prove that all nodes reliably have the same data then that provides strong general basis from which prove the integrity the system whole. the case bitcoin, the holds the transactions and the unspent transaction outputs, which allows nodes verify future transactions against double-spend. the case ethereum, holds what ammounts pointers machine state. proving the consistency across all nodes those data sets fundamental the integrity those systems. however, because have started with the assumption (see iii distributed systems independently only have considered confidence (rc still unclear how measure concrete confidence level psa realworld contexts and for real-world decisions, confidence mainly dependent (human) agent's vantage point, set data hand, and maybe even intuition. thus find more adequate call soft criteria. order comprehend this concept objectively and relate the notion conveyed woods the quote above, proceed defining the measure confidence aspect the conditional probability being the case given context: overall, wish provide system such that users can guaranteed that matter with which other individuals, systems organizations they interact, they can with absolute confidence the possible outcomes and how those outcomes might come about. psa p(a|c) where the context models all other information available the agent, including basic and intuitive assumptions. consider the fundamental example cryptographically signed messages with asymetric keys applied throughout the field cryptographic systems (basically what coins the term crypto-currency). the central aspect this context call asignature which provides with the ability know with certainty that given message's real author authorreal the same agent indicated solely via locally available data the message's meta information through the cryptographic signature authorlocal gain this confidence because deem very hard for any agent not possession the private key create valid signature for given message. the idea "absolute confidence" here seems important, and attempt understand more formally and generally for distributed systems. let psa measure the confidence agent has various aspects the system participates in, where represents confidence, and represents absolute confidence. let ... define set aspects about the system with which agent measures confidence. call the requirements with respect let (a) thresholding function for node with respect such that when psa e(a) then will either stop participating the system, reject the participation others (resulting fork). let and let partitions where e(a) e(a) (.) acting agents, any proof blockchain based system better understood choice (hence our use the =), that nodes use their agency decide when stop interacting with other nodes based detecting that the state longer matches. this might also called "proof enforcement," and also appropriately known fork because essentially results partitioning the network. the heart the matter has with the trust any single agent has the system. [eip-] section (driving factors) read: (.) any value rejected and any value e(a) rejected call the absolute requirements and the considered requirements. have formally separated system characteristics that have absolute confidence (ra from those asignature authorreal authorlocal (.) the appeal this aspect that can check authorship locally, i.e., without the need party direct trusted communication channel the real author. but, the confidence this aspect certain cryptographic system depends the context pssignature p(authorreal authorlocal |c) (.) constrain the context remove the possibility adversary gaining access agent's private key and also exclude the possible (future) existence computing devices algorithms that could easily calculate brute force the key, might then assign (constructed) confidence level i.e., "absolute confidence". without such constraints must admit that pssignature which real world events, for instance the mt.gox hack from make clear. aim describe these relationships such detail order point out that any set absolute requirements can't reach beyond trivial statements statements about the content and integrity the local state the agent itself. following descarte's way "most all the missing bitcoins were stolen straight out the mt. gox hot wallet over time, beginning late [nilsson] wish provide generalized means which decentralized multi-agent systems can built that: expend differing levels resources validate. designed holochain allow such validation functions set contextually per application and expose these contexts explicitly. thus, one could conceivably build holochain application that deliberately makes choices its validation functions implement either all partial characteristics blockchains. holochain, therefore, can understood framework that opens spectrum decentralized application architectures which blockchain happens one specific instance one end this spectrum. the following sections will show what categories validation algorithms exist and how these can stacked top each other order build decentralized systems that are able maintain integrity without introducing absolute truth every agent would forced accept consider. intrinsic data integrity every application but the most low-level routines utilize non-trivial, structured data types. structured implies the existence model describing how interpret raw bits instance type and how pieces the structure relate each other. often, this includes certain assumptions about the set possible values. certain value combinations might not meaningful violate the intrinsic integrity this data type. consider the example cryptographically signed message {body, signature, author}, where author given the form their public key. this data type conveys the assumption that the three elements body, signature and author correspond each other constrained the cryptographic algorithm that assumed determined through the definition this type. the intrinsic data integrity given instance can validated just looking the data itself and checking the signature applying the cryptographic algorithm that constitutes the central part the type's priori model. the validation yields result {true, alse} which means that the confidence the intrinsic data integrity absolute, i.e. psintrinsic generally, define the intrinsic data integrity transaction type aspect aph,intrinsic expressed through the existence deterministic and local validation function (t) for transactions that does not depend any other inputs but itself. note how the intrinsic data integrity the message example above does not make any assumptions about any message's real author, the aspect asignature from the previous section does. with this definition, focus aspects that don't make any claims about system properties non-local the agent under consideration, which roots the sequence inferences that constitutes the validity and therefore confidence system's high-level aspects and integrity consistent environmental inputs. questioning the confidence every thought, project his famous statement cogito ergo sum into the reference frame multi-agent systems stating: agents can only have honest confidence the fact that they perceive certain stimulus present and whether any particular abstract priori model matches that stimulus without contradiction, i.e., that agent sees certain piece data and that possible interpret certain way. every conclusion being drawn posteriori through the application sophisticated models the context dependent assumptions about the context that are inherent the model. this the heart the agent-centric outlook, and what claim must always taken into account the design decentralized multi-agent systems, shows that any aspect the system whole that includes assumptions about other agents and non-local events must i.e., have priori confidence facing this truth about multi-agent systems, find little value trying force absolute truth and instead frame the problem as: fit-for-purpose solutions can applied order optimize for application contextualized confidences psa violation any threshold e(a) through the actions other agents can detected and managed any agent, such that the system integrity maintained any point time or, when not, there path regain (see ??). perceive the agent-centric solution these requirements the holographic management systemintegrity within every agent/node the system through application specific validation routines. these sets validation rules lie the heart every decentralized application, and they vary across applications according context. every agent carefully keeps track their representation that portion reality that importance them within the context given application that has manage the trade-off between having high confidence thresholds e(a) and low need for resources and complexity. for example, consider two different use cases transactions: receipt email message where are trying validate spam not and commit monetary transaction where are trying validate against double-spend. these contexts have different consequences that agent may wish evaluate differently and may willing membranes provenance distributed systems must rely mechanisms restrict participation nodes processes that without such restriction would compromise systemic integrity. systems where the restrictions are based the nodes' identity, whether that declared type authority, collected from the history the nodes' behaviors, are know permissioned [swanson]. systems where these restrictions are not based properties the nodes themselves are known permissionless. permissionless multi-agent systems, principle threat systemic integrity comes from sybil-attacks [douceur], where adversary tries overcome the system's validation rules spawning large number compromised nodes. however, for both permissioned and permissionless systems, mechanisms exists gate participation. formally: e(h(t)) the case bitcoin and ethereum ignores the value and makes its determination solely whether demonstrates the "proof" proof-of-x work stake which sufficient gating protect against sybilattacks. giving the data-centric fallacy forcing one ab! solute truth reveals that can't discard transaction provenance. agent-centric distributed systems instead must rely two central facts about data: originates from source and its historical sequence local that source. for this reason, splits the system state data into two parts: each node responsible maintain its own entire source chain and ready confirm that state other nodes when asked and all nodes are responsible share portions other nodes' transactions and those transactions' meta data their dht shard meta data includes validity status, source, and optionally the source's chain headers which provide historical sequence. thus, the dht provides distributed access others' transactions and their evaluations the validity those (.) where the function maps from the range the hash function the nodes that keep the redundant shards the given transaction (see i). having the list nodes e(h(t)) allows agent compare third-party viewpoints regarding with its own and that the transaction's source(s). the randomization the hash function ensures that those viewpoints represent unbiased sample. can adjusted depending the application's constraints and the chosen trade-off between costs and system integrity. these properties provide sufficient infrastructure create system integrity detecting nodes that don't play the rules like changing the history content their source chain. appendix detail tooling appropriate for different contexts, including ones where detailed analysis source chain history required for example financial transaction auditing. depending the application's domain, neighborhoods could become vulnerable sybil-attacks because sufficiently large percentage compromised nodes could introduce bias into the sample used agent evaluate given transaction. holochain allows applications handle sybil-attacks through domain specific membrane functions. because chose inherently model agency within the system, permission can granted declined programmatic and decentralized manner thus allowing applications appropriately land the spectrum between permissioned and permissionless. appendix provide some membrane schemes that can chosen either for the outer membrane that application that nodes have cross order talk any other node within the application for any secondary membrane inside the application. that latter means that nodes could join permissionless and participate aspects the application that are not integrity critical without further condition but need provide certain criteria order pass the membrane into application crucial validation. thus, holochain applications maintain systemic integrity without introducing consensus and therefore (computationally expensive) absolute truth because any single node uses provenance independently verify any single transaction with the sources involved that transaction and because each holochain application let (n, ph, binary function that evaluates whether transactions type submitted are accepted, and where any arbitrary extra information needed make that evaluation. call the membrane function, and note that will component the validation function (t, from the initial formalism. transactions. this resembles how knowledge gets constructed within social fields and through interaction with others, described the sociological theory social constructivism. the properties the dht conjunction with the hash function provide with deterministically defined set nodes, i.e., neighborhood for every transaction. one cannot easily construct transaction such that lands given neighborhood. formally: recieved from those nodes will result changing mother runs independently all others, they are inherently permissioned application specific rules for joining and continuing participation that application's network. these both provide the benefit that any given holochain application can tune the expense that validation contextually appropriate level. let the function gabout (m) return set nodes important for node gossip about defined the properties define subsets gwith (m) according correlation with what means have low vs. high confidence value gossip world model (a) pull: consisting nodes about which low confidence means need for more frequent gossip raise node's confidence. such nodes would include those for which, with respect the given node, hold its published entries, hold entries also responsible for holding, are close the then node (i.e. its lowest kbucket), and which relies for routing (i.e. subset each k-bucket) (b) push: consisting nodes about which high confidence implies need for more frequent gossip spread the information about that node. such nodes would include ones for which given node has high confidence bad actor, i.e. has directly experienced bad acting, has recevied bad actor gossipe from nodes that has high confidence being able make that bad actor evaluation. far, have focused those parts the validation function used verify elments however, maintaining system integrity distributed systems also requires that nodes have mechanisms sharing information about nodes that have broken the validation rules that they can excluded from participation. there exist, additionally, forms bad-acting that not live the content transaction but the patterns transacting that are detrimental the system, for example, denial service attacks. holochain uses gossip for nodes share information about their own experience the behavior other nodes. informally call this information the node's world model this section describe the nature holochain's gossip protocols and how they build and maintain node's world model. described one such part the world model, the uptime metric and how used for maintaing redundant copies entries. defined membrane function that determines node shall accept transaction and allowed that function take arbitrary data the main source that data comes from this world model. more formally: recall that each node maintains set metrics about other nodes knows about. note that terms our formalism, this world model part each node's non-chain state data let tuple tuples: ((u, c)self (u, c)others which record experience node with respect given metric and confidence that exprience, both directly experienced "hearsay" recieved from other nodes. allow class entries stored used also metric which act signed declaration the experience regarding some other node. call such entries warrants. these warrants allow use the standard tooling holochain make provenance based, verifyable claims about other nodes the network, which propagate orthogonally from the usual dht methods, via gossip nodes that need "hear" about these claims make decisions about interacting with nodes. let the function gwith (m) return set nodes important for node gossip with defined probabilistc weighting that information todo: describe gossip trigger function based the pull vs. pull distinction that demostrates when gossip happens the computational costs gossip depend the set metrics that particular application needs keep track maintain system integrity. for application with very strong membership membrane perhaps only uptime metrics are necessary gossip about balance resillience. but this too may depend apriori knowledge the nodes involved the application. applications with very loose membership membranes may have substantial number metrics and complex membrane functions using those metrics which may require substantial compute effort. the holochain design intentionally leaves these parameters only loosly specificed that applications can built fit for purpose. calm logical monotonicity todo: description calm multi-agent systems, and how works our case complexity distributed systems this section discuss the complexity our proposed architecture for decentralized systems and compare the increasingly adopted blockchain pattern. formally describing the complexity decentralized multi-agent systems non-trivial task for which more complex approaches have been suggested ([marir]). this might the reason why there happens unclarity and misunderstandings within communities discussing complexity and scalability bitcoin for example [bitcoin reddit]. order able have ball-park comparison between our approach and the current status quo decentralized application architecture, proceed modeling the worst-case time complexity both for single node systemn ode well for the whole system system and both functions the number state transitions (i.e., transactions) and the number nodes the system transaction least flood through the network, block size and time can't pushed beyond and respectively, according [croman ethereum let ethereum the ethereum main network, the number transactions and the number fullclients within the network. the time complexity processing single transaction single node function the code that has its execution being triggered the given transaction plus constant: ftxi (n, bitcoin similarly bitcoin and result the blockchain design decision maintain one single state (n, "this avoided all costs the uncertainty that would ensue would likely kill all confidence the entire system." [eip-]), every node has process every transaction being sent resulting time complexity per node let bitcoin the bitcoin network, the number transactions and the number full validating nodes (i.e., miners within bitcoin for every new transaction being issued, any given node will have check the transaction's signature (among other checks, see. [bitcoinwiki]) and especially check this transaction's output not used any other transaction reject double-spendings, resulting time complexity ftxi (n, (.) per transaction. the time complexity big-o notation per node function the number transactions therefore: bitcoinn ode o(n (.) the complexity handled one bitcoin node does not depend the number total nodes the system. but since every node has validate exactly the same set transactions, the system's time complexity function number transactions and number nodes results bitcoin o(n (.) note that this quadratic time complexity bitcoin's transaction validation process what creates its main bottleneck this reduces the network's gossip bandwidth since every node has validate every transaction before passing along. order still have average for the sake simplicity and focusing lower bound the system's complexity, are neglecting all nodes that are not crucial for the operation the network, such light-clients and clients not involved the process validation not inherently that more participants will result more transactions but model both values separate parameters (.) c+n (.) that ethereumn ode o(n favg (n, m)) (.) whereas users are incentivized hold the average complexity favg (n, the code being run ethereum small since execution has payed for gas and which due restrictions such the block gas limit. other words, because the complexity ftxi (n, being burdened upon all nodes the system, other systemic properties have keep users from running complex code ethereum not bump into the network's limits. again, since every node has process the same set all transactions, the time complexity the whole system then that one node multiplied ethereum o(nm ftxi (n, m)) (.) blockchain both examples blockchain systems above need non-trivial computational overhead order work all: the proof-of-work, hash-crack process also called mining. since this overhead not function either the number transactions nor directly the number nodes, often omitted complexity analysis. with the total energy consumption all bitcoin miners today being greater than the country iceland [coppock], complexity dlog(m)e. (.) after receiving the state transition data, this node will gossip with its neighbors which will result copies this state transition entry being stored throughout the system different nodes. each these nodes has validate this entry which application specific logic which the complexity shall call v(n, m). combined, this results system-wide complexity per state transition given with dlog(m)e v(n, dht lookup (.) validation which implies the following whole system complexity o-notation holochain o(n (log(m) v(n, m)) (.) now, this the overall system complexity. order enable comparison, reason that the case holochain without loss generality (i.e., dependent the specific holochain application), the load the whole system shared equally all nodes. without further assumptions, for any given state transition, the probabil ity originating certain node the term for the lookup complexity needs divided describe the average lookup complexity per node. other than blockchain systems where every node has see every transaction, for the vast majority state transitions one particular node not involved all. the stochastic closeness the node's public key's hash with the entry's hash what triggers the node's involvement. assume the hash function show uniform distribution hash values which results the probability certain node being one the nodes that cannot discard this entry times the average time complexity being handled average node then holochainn ode (log(m) v(n, m)) (.) neglecting the complexity blockchain's consensus algorithm seems like silly mistake. blockchains set the block time, the average time between two blocks, fixed parameter that the system keeps homeostasis adjusting the hash-crack's difficulty according the network's total hash-rate. for given network with given set mining nodes and given total hash-rate, the complexity the hash-crack constant. but the system grows and more miners come on-line, which increases the networks total hashrate, the difficulty needs increase order keep the average block time constant. with this approach, the benefit higher total hashrate xhr increased difficulty adversary influence the system creating biased blocks (which would render this party able double-spend attacks). that why blockchains have subsidize mining, depending high xhr make economically impossible for attacker overpower the trusted miners. so, there direct relationship between the network's total trusted hash-rate and its level security against mining power attacks. this means that the confidence psblockchain any agent can have the integrity the system function the system's hash-rate xhr and more precisely, the cost/work cost(xhr needed provide it. looking only certain transaction and given any hacker acts economically rationally only, the confidence being added all has upper bound cost(xhr psblockchain (t) min (.) value(t) order keep this confidence unconstrained the mining process and therefore the architecture blockchain itself, cost(xhr (which includes the setup mining hardware well the energy consumption) has grow linearly with the value exchanged within the system. holochain let given holochain system, let the sum all public (i.e., put the dht) state transitions (transactions), let all agents trigger total, and let the number agents nodes) the system. putting new entry the dht involves finding node that responsible for holding that specific entry, which our case according [kademlia] has time private (see:) state transitions, i.e., that are confined local are completely within the scope node's agency and don't affect other parts the system directly and can therefore omitted for the complexity analysis distributed system note that the factor represents the average number state transactions per node (i.e., the load per node) and that though this highly application specific value, priori expected lower bound since nodes have process least the state transitions they produce themselves. the only overhead that added the architecture this decentralized system the node look-up with its complexity log(m). the unknown and also application specific complexity v(n, the validation routines what could drive the whole system's complexity still. and indeed conceivable think holochain applications with lot complexity within their validation routines. basically possible mimic blockchain's consensus vali- dation requirement enforcing that validating node communicates with all other nodes before adding entry the dht. could well only half all nodes. and there surely host applications with only little complexity specific state transitions within application that involve only little complexity. holochain app one can put the complexity where needed and keep the rest the system fast and scalable. section proceed providing real-world use cases and showing how non-trivial holochain applications can built that get along with validation complexity o(), resulting total time complexity per node o(log(m)) and high enough confidence integrity without introducing proof-of-work all. vi. use cases social media network transport: libpp including end-to-end encryption. javascript virtual machine: otto https://github.com/robertkrimen/otto. lisp virtual machines: zygomys https://github.com/glycerine/zygomys. additionally have created benchmarking suite examine the processing, bandwidth and storage used various scenarios, and compared these with ethereum applications similar scenarios. these can seen here: https://github.com/holochain/benchmarks have yet implement scalability tests for large scale applications, but our roadmap.todo appendix dhthc dhtputlink (base, link, tag) where base and link are keys and where tag arbitrary string, which associates the tuple {link,tag} with the key base. dhtgetlinks (base, tag) where base key keys and where tag arbitrary string, which returns the set links base identified tag. consider simple implementation micro-blogging using holochain where: {fpost (text, node), ffollow (node), fread (text)} and {fisoriginator dht: customized version libpp/ipfs's kademlia implementation. now present few use cases applications built holochain, considering the context the use case and how affects both complexity and evaluation integrity and thus validation design. lines code. dhtmod (key, newkey) where key and newkey are keys, which adds newkey modifier skey and calls dhtputlink (key, newkey, "replacedby"). describe o() complexity dhtdel (key) where key key, and marks skey deleted. dpki identity modification dhtget mod del. appendix fsys money mutual-credit vs. coins where the complexity the transaction higher, complexity may o(n o(log(n)) see holo currency white paper: vii. implementation the time this writing have fully operational implementation system described this paper, that includes two separate virtual machines for writing dna functions javascript, lisp, along with proofof-concept implementations number applications including twitter clone, slack-like chat system, dpki, and set mix-in libraries useful for building applications. all the other sys functions... appendix patterns trust management tools holochain available app developers for use considered requirements, some which are also used the system level and globally parameterized for application: countersigning todo notaries todo "the network the notary." publish headers e.g. for chain-rollback detection source-chain examination. todo blocked-lists. e.g. ddos, spam, etc ments/passports/identity cards within the agent entry (second entry ... more here... appendix membranes invitation one the most natural approaches for membrane crossing space which agents provide identity rely invitation agents that are already the membrane. this could invitation: anyone admin (that could either set the application's dna variable shared within the dht both could mutable constant) multiple users (applying social triangulation) proof-of-service cryptographic proof delivery service hosting application. intend leverage this technique with our distributed cloud hosting application holo, which will build top holochain. see our holo hosting white paper for much more detail proof-of-work the application's requirement not anonymity, other than the cryptographic hash-cracking work applied most the blockchains, this could also useful work that new members are asked contribute the community puzzle proof domain knowledge. examples are: test for knowledge about local maps proof citizenship dna sequencing protein folding seti proof-of-identity reputation given the presence other applications/chains, these can used attach the identity and its reputation that chain the agent that wants join. since this seems crucial pillar the ecosystem holochain applications, plan deliver system-level application called dpki (distributed public key infrastructure) that will function the main identity and reputation platform. prototype this app was already developed prior the writing this paper. publication scientific article proof-of-stake payment depost payment have agent certified. immune system blacklisting nodes that don't play the application rules. proof-of-presence use notarized acknowledgments docu- thank steve sawin for his review this paper, latex support and much more.... [dupont] quinn dupont. experiments algorithmic governance: history and ethnography the dao, failed decentralized autonomous organization http://www.iqdupont.com/assets/documents/ dupont--preprint-algorithmic-governance.pdf [eip-] gavin wood. ethereum: secure decentralised generalised transaction ledger. http://yellowpaper.io/ [kademlia] petar maymounkov and david mazieres kademlia: peer-to-peer information system base the xor metric https://pdos.csail.mit.edu/~petar/papers/ maymounkov-kademlia-lncs.pdf [zhang] zhang, h., wen, y., xie, h., yu, distributed hash table theory, platforms and applications [croman kyle croman, christian decker, ittay eyal, adem efe gencer, ari juels, ahmed kosba, andrew miller, prateek saxena, elaine shi, emin sirer, dawn song, roger wattenhofer, scaling blockchains, financial cryptography and data security, springer verlag [bitcoin reddit] /u/mike hearn, /u/awemany, /u/nullc al. https://www.reddit.com/r/bitcoin/comments/ afv/mike_hearn_on_those_who_want_all_scaling_ to_be/csaexw/?context=&st=jjfakq&sh=e reddit discussion [marir] marir, toufik and mokhati, farid and bouchelaghem-seridi, hassina and tamrabet, zouheyr", complexity measurement multi-agent systems", multiagent system technologies: german conference, mates stuttgart, germany, september proceedings, springer international publishing https://doi.org/./----_ [coppock] mark coppock the worlds cryptocurrency mining uses more electricity than iceland https://www.digitaltrends.com/computing/ national bitcoin-ethereum-mining-use-significant-electrical-power/ fiptps.pdf international workshop peer-to[bitcoinwiki] bitcoin protocol peer systems. retrieved april https://en.bitcoin.it/wiki/protocol_rules#.tx. [holocurrency] arthur brock and eric harris-braun _messages bitcoin wiki holo: cryptocurrency infrastructure for global scale and [ipfs] juan benet ipfs content addressed, versioned, stable value file system (draft https://holo.host/holo-currency-wp/ https://ipfs.io/ipfs/qmrgsqmcxeagayrzndefqvulxokzrjalx/ [nilsson] nilsson, kim april the missing mtgox ipfs.draft.pdf bitcoins". retrieved december [libpp] juan benet, david dias libpp specification http://blog.wizsec.jp/// https://github.com/libpp/specs the-missing-mtgox-bitcoins.html [oxford] oxford online dictionary [swanson] tim swanson consensus-as-a-service: brief https://en.oxforddictionaries.com/definition/ report the emergence permissioned, distributed provenance ledger systems april [douceur] douceur, john (). "the sybil attack" https://pdfs.semanticscholar.org/fa/ https://www.microsoft.com/en-us/research/ daafcfcdaeacdffcbc.pdf publication/the-sybil-attack/?from=http%a% f%fresearch.microsoft.com%fpubs%f%