decentralized video delivery and streaming network powered new blockchain last updated: nov version abstract this whitepaper introduces the theta network, new blockchain and token the incentive mechanism for decentralized video streaming and delivery network. the theta network and protocol solves various challenges the video streaming industry faces today. first, tokens the theta blockchain are used incentive encourage individual users share their redundant computing and bandwidth resources caching relay nodes for video streams. this improves the quality stream delivery and solves the "last-mile" delivery problem, the main bottleneck for traditional content delivery pipelines, especially for high resolution high bitrate and next generation streams. second, with sufficient network density the majority viewers will pull streams from peering caching nodes, allowing video platforms significantly reduce content delivery network (cdn) costs. more importantly, introducing tokens end-user incentive mechanism the theta network allows video platforms deepen viewer engagement, drive incremental revenues, and differentiate their content and viewing experience from their competitors. the theta blockchain introduces three main novel concepts: multi-level bft: modified bft consensus mechanism which allows thousands nodes participate the consensus process, while still supporting very high transaction throughput (,+ tps). the core idea have small set nodes, which form the validator committee, produce chain blocks fast possible using pbft-like process. then, the thousands consensus participants, called guardians, finalize the chain generated the validator committee regular checkpoint blocks. the name multi-level bft consensus mechanism reflects the fact that the validator/guardian division provides multiple levels security guarantee. the validator committee provides the first level consensus with validators, the committee can come consensus quickly. the guardian pool forms the second line defense. with thousands nodes, substantially more difficult for attackers compromise the integrity the network, and thus provides much higher level security. believe this mechanism achieves good balance among transaction throughput, consistency, and level decentralization, the three pillars the so-called "impossible triangle". aggregated signature gossip scheme: basic all-to-all broadcasting the checkpoint block hash could work between guardian nodes, but yields quadratic communication overhead, and therefore cannot scale nodes. instead, propose aggregated signature gossip scheme which significantly reduces messaging complexity. each guardian node keeps combining the partially aggregated signatures from all its neighbors, and then gossips out the aggregated signature. this way the signature share each node can reach other nodes exponential rate, leveraging the gossip protocol. addition, the signature aggregation keeps the size the node-to-node messages small, and thus further reduces the communication overhead. resource oriented micropayment pool: off-chain "resource oriented micropayment pool" that purpose-built for video streaming. allows user create off-chain micropayment pool that any other user can withdraw from using off-chain transactions, and double-spend resistant. much more flexible compared off-chain payment channels. this white paper will describe these concepts and the theta blockchain detail. the theta network launched with erc-compliant tokens and were integrated into the sliver.tv platform december the theta blockchain mainnet code has been released, and the first live mainnet implementation planned launch march which time each erc theta token will exchanged for native theta tokens. table contents vision introduction background opportunity video streaming market video streaming challenges theta mesh delivery network geo-optimized tracker server intelligent player client theta blockchain ledger the consensus mechanism multi-level bft system model the block settlement process block proposal block consensus among validators analysis the block finalization process scaling thousands guardians analysis reward and penalty for validators and guardians turing-complete smart contract support off-chain micropayment support resource oriented micropayment pool double spending detection and penalty analysis ledger storage system storage microservice architecture history pruning state synchronization dual currency system and token mechanics future work founding advisory team vision introduction video streaming market live video streaming accounts for over two-thirds all internet traffic today, and expected jump according cisco's june visual networking index report. the us, millennials between the ages and are driving the growth video streaming, and are heavy users services like netflix, youtube, and hbo. streaming video among this group has jumped from average hours per week hours per week according ssrs media and technology survey, and mobile devices are leading the charge video consumption growing and the top five video streaming players the are facebook, google/youtube, twitter and related properties, live.ly and twitch. figure global video traffic growth the same time, global virtual reality (vr) traffic including deg video streaming content estimated grow -fold staggering cagr according the same cisco report. https://www.cisco.com/c/dam/global/ko_kr/assets/pdf/-vni-complete-forecast-pt.pdf http://www.zenithmedia.com/mobile-drive---increase-online-video-consumption-/ figure global virtual reality traffic growth video streaming challenges content delivery networks (cdn) play important role the video streaming ecosystem. provides the backbone infrastructure deliver the video streams end viewers. one major limitation today's cdn networks the so-called "last-mile" delivery problem. typically, cdn providers build data centers called point-of-presence (pops) many locations around the world, with the expectation that these pops are geographically close the viewers. however, the number pops are limited, hence are not near enough the majority viewers, especially less developed regions. this "last-mile" link usually the bottleneck today's streaming delivery pipeline and often leads less optimal user experience including choppy streams, bad picture quality, and frequent rebuffering. streaming sites and content platforms, another major concern the cdn bandwidth cost. for popular sites, the cdn bandwidth cost can easily reach tens millions dollars per year. even platforms own proprietary cdns, maintenance costs are often high. these issues are becoming even more prominent with the coming era deg streaming, and upcoming technologies such light field streaming. table compares the bandwidth requirements today's mainstream p/hd streams deg and future lightfield streams, quickly jumping orders magnitude. https://www.cisco.com/c/dam/global/ko_kr/assets/pdf/-vni-complete-forecast-pt.pdf standard resolution bandwidth mbps magnitude uhd deg deg lightfield --- table bandwidth comparison: today's p/p video and deg streaming, future volumetric/lightfield streaming solve the and light field video delivery problem, the industry has started explore "foveated streaming" technology. instead streaming the entire video full resolution, this technology reduces the image quality the peripheral vision (outside the zone gazed the fovea) order reduce bandwidth requirements. the viewer turns his her head look different direction, the system adapts the spatial video resolution accordingly fetching the high resolution video packets for the viewing direction from the server. for the foveated streaming technology work well practice, the round-trip time between the server and the viewer has small enough. for viewers that are geographically further from the cdn pops, their stream viewing experience compromised even with foveated streaming technology. background sliver.tv (the "company") has been the forefront developing next-generation video streaming technologies for and spherical deg video streams since and the parent company theta labs, inc.. sliver.tv has raised over million venture financing from notable silicon valley vcs including danhua capital, dcm, sierra ventures, leading hollywood media investors including creative artists agency, bdmi, advancit capital, greycroft gaming track fund, and marquee corporate investors including gree, colopl, samsung next and sony innovation funds. additionally, the company has strong chinese investors and partners including heuristic capital partners, capital, green pine capital partners, and sparkland. technology derived from "foveated streaming" sliver.tv's most recent technology patent granted #,,, "methods and systems for non-concentric spherical projection for multi-resolution view", specifically addresses the problem generating highly efficient spherical videos for virtual reality (vr) streaming, highlight, and replay. the technology performs non-concentric spherical projection derive high resolution displays selected important game actions concurrently with lower resolution displays static game environments, thus optimizing tradeoff between visual fidelity and data transfer load. sliver.tv today the leading next-generation live esports streaming platform with over six million unique visits july with vision transform the esports engagement experience. video gaming has grown popularity become billion market, bigger than hollywood and bollywood combined, the rise multiplayer competitive gaming https://patents.google.com/patent/usb spectator sport has become major new industry, dubbed esports. esports global phenomenon with major tournaments and major pockets fans and competitive teams europe, asia and north america. the online gaming and esports ecosystems have exploded over the past five years. recent superdata research put the combined audience for gaming video content youtube and twitch million, more than twice the population. this surpasses the viewership million for hbo and netflix combined. today, esports and gaming video content account for significant portion all video content streamed over the internet. sliver.tv additional core patents and technology focus various applications cutting edge live streaming esports content. the company's patent #,, "methods and systems for virtual reality streaming and replay computer video games", patent #,, "methods and systems for game video recording and virtual reality replay" and patent #,, "methods and systems for computer video game streaming, highlight, and replay" pioneer the capture and live rendering popular esports games including league legends, dota and counter-strike: global offensive fully immersive deg spherical video stream, effectively placing the viewer and audience inside the game through live video stream, and rendering deg highlights, replays and special effects real-time. since launching sliver.tv has broadcast numerous global esports tournaments partnership with premier brands including esl one, dreamhack and intel extreme masters. key events the and europe, sliver.tv has live streamed top esports games millions fans counter-strike: global offensive (cs:go) and league legends (lol). sliver.tv launched its watch win esports platform july and the first virtual token designed around esports content streaming and fan engagement. since launch, the company has attracted millions esports fans circulating over billion virtual tokens actively participating and engaging with live esports matches. these users viewed over million minutes live esports streaming, nearly years worth content the first few weeks launch. this positions the company one the largest esports streaming sites built around virtual community today. the sliver.tv platform continuing expand quickly driven word-of-mouth, referral and social channels. https://www.superdataresearch.com/market-data/gaming-video-content/ https://www.google.com/patents/us https://www.google.com/patents/us https://patents.google.com/patent/usb https://venturebeat.com////polands-intel-extreme-masters-was-biggest-event-in-esports-history/ https://www.sliver.tv/press figure total visits desktop and mobile web, the last months opportunity the company's mission leverage blockchain technology create the first decentralized video streaming and delivery network whereby video viewers are incentivized share redundant computing and bandwidth resources address today's video streaming challenges. using the ethereum evm "world computer" metaphor, the theta network can viewed the "world cache" formed the memory and bandwidth resources contributed viewers. specifically, viewers around the globe can contribute their devices "caching nodes" whereby they form video delivery mesh network that responsible for delivering any given video stream viewers anywhere around the world optimized for local. the theta network can effectively address the technical challenges discussed the previous section. first, viewers' devices are geographically much closer each other than the cdn pops. this reduces packet round-trip time and improves the stream delivery quality, and thus addresses the "last-mile" delivery issue. second, with sufficient amount caching nodes, most viewers will receive the stream from caching nodes, which will help streaming sites reduce their cdn bandwidth cost. third, caching nodes also reduce round-trip time making foveated and next generation streaming technology practical. encourage viewers contribute their computing and bandwidth resources, introduce the theta token incentive mechanism. caching nodes can earn tokens they relay video streams other viewers. not only does the theta token motivate viewers join the network caching nodes, also greatly improves the streaming market efficiency streamlining the video delivery process. will discuss later the paper, but within the theta network, advertisers can also directly target viewers lower cost, viewers earn theta tokens for their attention and engagement with their favorite content, and influencers earn theta token gifts directly from viewers. more interestingly, streaming and content platforms can open new and incremental revenue opportunities with theta. the full launch the theta protocol introduces new blockchain and native token structure where: caching nodes earn tokens for caching and relaying video streams other viewers viewers optionally earn tokens from advertisers engagement rewards, and can turn gift favorite influencers and content creators streaming sites and platforms can drive incremental new revenues through sales premium goods and services, and deepen user engagement through theta advertisers fund advertising campaigns with tokens support influencers, streaming sites and viewers streaming sites and platforms can offload cdn costs the theta protocol builds upon the following novel concepts: multi-level bft: modified bft consensus mechanism which allows thousands nodes participate the consensus process, while still supporting very high transaction throughput (,+ tps). the core idea have small set nodes, which forms the validator committee, produce chain blocks fast possible using pbft-like process. then, the thousands consensus participants, called the guardians, can finalize the chain generated the validator committee regular checkpoint blocks. the name multi-level bft consensus mechanism reflects the fact that the validator/guardian division provides multiple levels security guarantee. the validator committee provides the first level protection with validators, the committee can come consensus quickly. the guardian pool forms the second line defense. with thousands nodes, substantially more difficult for attackers compromise, and thus provides much higher level security. believe this mechanism achieves good balance among transaction throughput, consistency, and level decentralization, the three pillars the so-called "impossible triangle". aggregated signature gossip scheme: naive all-to-all broadcasting the checkpoint block hash could work between guardian nodes, but yields quadratic communication overhead, and cannot scale nodes. instead propose aggregated signature gossip scheme which could significantly reduce messaging complexity. each guardian node keeps combining the partially aggregated signatures from all its neighbors, and then gossips out the aggregated signature. this way the signature share each node can reach other nodes exponential speed thanks the gossip protocol. addition, the signature aggregation keeps the size the node-to-node messages small, and thus further reduces the communication overhead. resource oriented micropayment pool: off-chain "resource oriented micropayment pool" that purpose-built for video streaming. allows user create off-chain micropayment pool that any other user can withdraw from using off-chain transactions, and double-spend resistant. much more flexible compared off-chain payment channels. particular, for the video streaming use case, allows viewer pay for video content pulled from multiple caching nodes without on-chain transactions. replacing on-chain transactions with off-chain payments, the built-in "resource oriented micropayment pool" significantly improves the scalability the blockchain. theta mesh delivery network peer-to-peer streaming focuses timely delivery audio and video content under strict, near real-time parameters. peer-to-peer livestream delivery works best when many people tune for the same stream the same time. high concurrent user count means more peering resources are available, and thus the peer nodes can pull the stream from each other more effectively. the whole system capacity increases more peer nodes become available. moreover, robustness the system increased peer-to-peer network, nodes not need rely centralized server retrieve content. this especially important cases server failure. contrast, for centralized cdn-based delivery, high concurrent users instead place scalability pressures the cdn servers. however, the shortcoming pure peer-to-peer streaming availability. peers come and anytime, which makes difficult predict the availability any given peer node. there are also uncontrollable differences nodes, such upload and download capacities. the other hand, cdn service more reliable and robust, and hence can serve reliable "backup" when the stream not available from peer nodes. our goal achieve maximum cdn bandwidth reduction without sacrificing the quality-of-service (qos) which critical established streaming platforms such netflix, youtube, twitch, facebook and others. this means whenever possible want the peer nodes pull the stream from each other instead from the cdn. achieve this goal, it's crucial for the peer nodes able identify neighboring nodes effectively. node can identify multiple peers close proximity, chances are that can find peers that can provide the video stream segments much more consistently. the contrary, the identified peers are "further away" terms network hops, nodes might not able pull stream from peers consistently and cause degraded user experience like stuttering, frequent rebuffering, etc. address this problem, theta has designed and currently implementing strategy which combines both hyper-optimized tracker server and player client-side intelligence. essentially, the tracker server provides high level guidance (e.g. list candidate peers) for the player client, while the player client implements peer filtering algorithm finer granularity based multiple variables find the neighboring nodes that can best serve them. figure interactions between the tracker servers and player clients geo-optimized tracker server order provide list candidate peer nodes each client, the tracker server records the location information whenever peer joins the network, including its address, latitude/longitude, and number other performance parameters. with this information the server can organize the nodes spatial database. theta's "hyper-optimized" spatial database optimized for storing and querying data that represents objects defined geometric space. peer node joins the network, the server can perform spatial query retrieve list candidate peers that are the close proximity very quickly and efficiently, see figure the tracker servers and the spatial databases can maintained video streaming sites that use the theta network and/or community peers for content delivery. mentioned earlier, peer node might leave the network anytime. hence the tracker server also needs aware which nodes are active. achieve this, active peer node needs maintain socket connection with the server and send heartbeat signals consistently. the server doesn't receive heartbeat for certain amount time, considers that peer node having left the network, and updates the spatial database accordingly. important distinction that the "distance" between two peer nodes measured the number router hops between them rather than the geographical distance. typically network distance and geographical distance are highly correlated, but aren't necessarily equivalent. for example, two computers could sit next each other physically, but connect different isps there might many hops between them. hence, aside from geographical information, the tracker server also utilizes the connectivity between the addresses collected the past analyze and select neighbor candidates. for example, candidates returned the spatial query can through another filter exclude those that are not connected the same isp the viewer's. intelligent player client each peer node may act both viewer, caching node both. the node launches, during the handshake step, retrieves list candidate peers from the tracker server for the livestream it's playing. then, performs speed and availability test select subset that has optimized performance, connectivity and can reliably provide the video stream segments. the client performs the speed and availability tests regularly during live stream session and continuously refines its neighbor list. figure player stream data buffer handling avoid qos degradation, local buffer management critical. the client player maintains local cache buffer the downloaded stream data figure the duration the cached stream data less than certain threshold, the player checks with the neighboring peers see they have the desired video stream segment. the event when none the neighbors has that segment, the player intelligently falls back the cdn. achieve the best qos possible, the player fetches updated candidate list from the tracker server regular basis during the stream session. the first version the client video player web/html based player which employs the webrtc protocol for stream delivery among peers. deploying web-based players requires minimal effort. streaming sites and platforms simply embed the player onto their webpages, and instantly has access and "launches" millions end user nodes the theta mesh network. thus, the deployment theta's mesh streaming technology very light-weight and frictionless. theta also plans release desktop and mobile client support. the advantage desktop client app over the web/html player that can run the background facilitate video stream relay (with the consent the user) even when the end user not watching any video streams. further, theta investigating dedicated hardware, iot devices, smarttvs and related approaches that are specifically designed for stream relay and re-broadcast. such devices can provide potentially better availability and bandwidth. theta blockchain ledger the theta ledger decentralized ledger designed for the video streaming industry. powers the theta token ecosystem which incentives end users share their redundant bandwidth and storage resources, and enables them engage more actively with video platforms and content creators. realize these goals, number challenges, many which are unique for video streaming applications, need tackled. one such challenges support ultra high transaction throughput. although many blockchain projects are facing transaction throughput problems, scaling for live video streaming different and possibly even more complex. typically, video segments are couple seconds long. achieve the finest granularity token reward one micropayment per video segment even live stream with moderate ten thousand concurrent viewers could generate couple thousand microtransactions per second, which far exceeds the maximum throughput today's public chains, such bitcoin and ethereum. popular live streams like major esport tournaments can attract more than one million viewers watching one stream simultaneously, not mention multiple concurrent live streams, which could potentially push the required transaction throughput the range millions per second. byproduct the high throughput rapidly growing storage consumption. storing the micropayment transactions highly storage demanding. with tens thousands transactions added the ledger every second, the storage space ordinary computer could run out quickly. video streaming applications typically require fast consensus. for bandwidth sharing rewards, the users that contribute redundant bandwidth typically want the payment confirmed before sending the next one. other use cases, such virtual gift donations live stream hosts, also require short confirmation times enable real-time interactions between the hosts and audience. finally, any blockchain, security the ledger critical. security highly correlated with the level decentralization. proof-of-stake (pos) based consensus mechanism, decentralization means even stake distribution among consensus participants. ideally, the consensus mechanism should allow thousands independent nodes, each with similar amounts stake and each possessing local copy the blockchain, participate the block finalization process. compromise such system, significant amount independent nodes would need controlled the attackers, which difficult achieve. achieve these goals, have designed our pos consensus algorithm based the byzantine fault tolerance (bft) protocols, which offers good guarantees such consistency (a.k.a. safety) when more than nodes running the ledger software are honest. however, the traditional bft algorithms not allow high level decentralization. they typically incur o(n) messaging complexity even for the normal (non-faulty proposer) case, where the number nodes participating the consensus protocol. when have thousands nodes, will take considerable amount time reach agreement. this paper, present novel multi-level bft consensus mechanism that allows mass participation, and still achieves tps throughput with the transaction confirmation time short few seconds. such level transaction throughput, although already much higher than bitcoin and ethereum, still not sufficient handle the micropayments for the "pay-per-byte" granularity. further increase the throughput, the theta ledger provides native support for off-chain scaling, with "resource oriented micropayment pool" which further amplifies the supportable throughput several order magnitudes. note that the off-chain payment support not only boosts the throughput, but also decreases the number the transactions that need stored the blockchain. top that, introduce the technique state and block history pruning further reduce the storage space requirement. moreover, have adopted the microservice architecture for the storage system, which can adapt different types machines and storage backends, powerful server clusters running data centers, commodity desktop pcs. the consensus mechanism multi-level bft the theta ledger built novel multi-level bft consensus mechanism which allows thousands nodes participate the consensus process, while still supporting very high transaction throughput tps). the core idea have small set nodes, which forms the validator committee, produce chain blocks fast possible using pbft-like process. with sufficient number validators (e.g. the validator committee can produce blocks fast speed, and still retain high degree difficulty prevent adversary from compromising the integrity the blockchain. hence, reasonable expect that there very high probability the validators will produce chain blocks without forks. then, the thousands consensus participants, called guardians, can finalize the chain generated the validator committee. here "finalization" means convince each honest guardian that more than all the other guardians see the same chain blocks. since there are many more guardians than validators, could take longer time for the guardians reach consensus than the validator committee. order for the guardians finalize the chain blocks the same speed that the validator committee produces new blocks, the guardian nodes can process the blocks much coarser grain. more specific, they only need agree the hash the checkpoint blocks, i.e. blocks whose height are multiple some integer (e.g. this "leapfrogging" finalization strategy leverages the immutability characteristic the blockchain data structure long two guardian nodes agree the hash block, with overwhelming probability, they will have exactly the same copy the entire blockchain that block. finalizing only the checkpoint blocks gives sufficient time for the thousands guardians reach consensus. hence, with this strategy, the two independent processes, i.e., block production and finalization, can advance the same pace. under the normal condition, finalizing checkpoint block similar the "commit" step the celebrated pbft algorithm since each guardian has already stored the checkpoint block locally. moreover, the checkpoint block has been signed the validator committee, and hence highly likely that all the honest guardians have the same checkpoint. thus, only need protocol for the honest guardians confirm that indeed more than all guardians have the same checkpoint hash. for more depth discussion, please refer our multilevel bft technical report: https://github.com/thetatoken/thetaprotocolledger/blob/master/docs/multilevelbfttechreport.pdf castro al. practical byzantine fault tolerance implement this protocol, naive all-to-all broadcasting the checkpoint block hash could work, but yields quadratic communication overhead, and cannot scale large numbers guardians. instead propose aggregated signature gossip scheme which could significantly reduce messaging complexity. the core idea rather simple. each guardian node keeps combining the partially aggregated signatures from all its neighbors, and then gossips out the aggregated signature, along with compact bitmap which encodes the list signers. this way the signature share each node can reach other nodes exponential speed utilizing the gossip protocol. within o(log iterations, with high probability, all the honest guardian nodes should have string which aggregates the signatures from all other honest nodes there network partition. addition, the signature aggregation keeps the size the node-to-node messages small, and thus further reduces the communication overhead. mentioned above, the validator committee comprised limited set validator nodes, typically the range ten twenty. they can selected through election process, randomized process, and may subject rotation improve security. eligible join the validator committee, node needs lock certain amount stake for period time, which can slashed malicious behavior detected. the blocks that the committee reaches consensus are called settled blocks, and the process settle the blocks called the block settlement process. the guardian pool superset the validator committee, i.e. validator also guardian. the pool contains large number nodes, which could the range thousands. with certain amount tokens locked for period time, any node the network can instantly become guardian. the guardians download and examine the chain blocks generated the validator committee and try reach consensus the the checkpoints with the above described "leapfrogging" approach. allowing mass participation, can greatly enhance the transaction security. the blocks that the guardian pool has reached consensus are called finalized blocks, and the process finalize the blocks called the block finalization process. the name multi-level bft consensus mechanism reflects the fact that the validator/guardian division provides multiple levels security guarantee. the validator committee provides the first level protection with validators, the committee can come consensus quickly. yet resistant enough attacks fact, already provides similar level security compared the dpos mechanism each validator nodes run independent entity. thus, transaction can already considered safe when has been included settled block, especially for low stake transactions. the guardian pool forms the second line defense. with thousands nodes, substantially more difficult for attackers compromise blockchain integrity, and thus provides much higher level security. the unlikely event that the validator committee fully controlled attackers, the guardians can re-elect the validators, and the blockchain can restart, advancing from the most recent block finalized the guardians. transaction considered irreversible when included finalized block. believe this mechanism achieves good balance among transaction throughput, consistency, and level decentralization, the three corners the so-called "impossible triangle". the multi-level security scheme suits video streaming applications well. for streaming platforms, most the transactions are micropayments (e.g. payment for peer bandwidth, virtual gifts hosts, etc.) which typically have low value, but require fast confirmation. for such low stake payments, the users only need wait for block settlement, which very fast, matter seconds. for high stake transfers, the user can wait longer until the block containing the transaction finalized, which could take slightly longer time, but still the range minutes. system model before diving into the details the block settlement and finalization process, first list our assumptions the system. for ease discussion, without loss generality, below assume each node (be validator guardian) has the same amount stake. extending the algorithms the general case where different nodes have different amount stake straightforward. validator committee failure model: there are validator nodes total. most the time, most one-third them are byzantine nodes. they might fully controlled attackers, but this happens only rarely. also assume that between any pair validator nodes there direct message channel (e.g. direct tcp connection). guardian pool failure model: there are guardian nodes total. any moment, most one-third them are byzantine nodes. not assume direct message channel between any two guardians. messages between them might need routed through other nodes, some which could byzantine nodes. timing model: assume the "weak synchrony" model. more specific, the network can asynchronous, even partitioned for bounded period time. between the asynchronous periods there are sufficiently long periods time where all message transmissions between two honest nodes arrive within known time bound will discuss later the paper, during the asynchronous period, the ledger simply stops producing new blocks. will never produce conflicting blocks even with network partition. during synchronous phases, block production will naturally resume, and eventual liveness can achieved. attacker model: assume powerful attackers. they can corrupt large number targeted nodes, but more than one-third all the guardians simultaneously. they can manipulate the network large scale, and can even partition the network for bounded period time. yet they are computationally bounded. they cannot forge fake signatures, and cannot invert cryptographic hashes. the block settlement process block settlement the process which the validator committee reaches agreement and produces chain blocks for the guardian pool finalize. inspired recent proof-of-stake research works including tendermint, casper ffg, and hot-stuff, have designed and implemented the block settlement algorithm described below. employs rotating block proposer strategy where the validators take turns propose new blocks. then, the committee votes the blocks determine their order using protocol similar casper ffg and hot-stuff. buchman al. tendermint: byzantine fault tolerance the age blockchains buterin al. casper the friendly finality gadget yin al. hotstuff: bft consensus the lens blockchain block proposal the validators rotate round robin fashion play the role block proposer, which responsible for proposing the next block for the validator committee vote on. enable the round robin rotation, each proposer maintains local logical clock called epoch. assuming there are validators, during epoch the validator with index mod elected the proposer for that epoch. note important that: the epoch should not stalled the liveness the proposer rotation guaranteed; and the epoch different validators should mostly sync, i.e. most the time all the validators have the same value, they can agree which node should produce the next block. below our protocol for proposer election and block proposal. algorithm round robin block proposal proposer voted false, received false, timeout false loop begin proposer mod (proposer self.index) and (not proposed yet) begin node elected the proposer propose one block end voted the node has proposed voted for block for epoch received the node has received epochchange(t messages timeout timeout reached voted received timeout begin broadcast message epochchange(t end the node has received epochchange(t messages begin enters epoch voted false, received false, timeout false end sleep for some time end algorithm the round robin block proposal protocol the protocol defines message epochchange(t which can viewed synchronization message passed among the validators assist them advance the next epoch together. essentially, validator broadcasts message epochchange(t all other validators any the following conditions met: the node has proposed voted for block epoch the node has received epochchange(t messages from other validators, the node timed out for epoch (the timeout set the other hand, the validator enters epoch when has received epochchange(t+) messages from other nodes. here show that this protocol meets the above two requirements. eventual progression: all the honest nodes will eventually enter epoch the worst case, all the honest nodes (at least nodes) reach timeout and broadcast the epochchange(t+) messages. under the timing model assumption, all these messages will delivered within time after being sent out. thus each honest node will receive least epochchange(t messages, and then enters epoch epoch synchrony: intuitively, this means the epochs all the honest nodes "move together". more precisely, claim that the time any two honest nodes enter epoch differ most most prove this, note that since there are most faulty nodes, for the first honest node enter epoch least other honest nodes must have broadcasted the epochchange(t messages. this honest node then also broadcasts epochchange(t message following the protocol. after most any honest node should have received least epochchange(t messages, which triggers them also broadcast the epochchange(t message. after all the honest nodes receive epochchange(t messages and enter epoch thus, most after the first honest node enters epoch the last honest node will enters the same epoch. practice, when the network latency small enough, all the honest nodes should enter epoch almost the same time. result, they can agree who the next proposer. also note that for the actual implementation, the epochchange(t messages can combined with other types messages (e.g. block votes) improve the efficiency. that the normal case (no proposer failure), additional synchronization overhead added the system for epoch changes. block consensus among validators the protocol settle proposed blocks involves pbft-based voting procedure among all validators, similar casper ffg and hot-stuff. the theta ledger blockchain, the header each block contains hash pointer its parent block (i.e. the previous block the chain), similar bitcoin and ethereum. two blocks are conflicting neither block ancestor the other. there are multiple, conflicting block proposals for the same epoch, honest validator keeps all them until one becomes settled, and then discards all conflicting blocks. the block settlement protocol operates epoch epoch. the proposer for the current epoch sends all validators block proposal. validator reacts broadcasting vote for the block. all messages are signed their senders. the header the proposed block might carry commit-certificate, which consists least (m/ signed votes for its parent block. note that under the assumption that more than validators are faulty, most one block per height can obtain commit-certificate. commit-certificate for block indicates this block and all its predecessors are committed. the proposed block may carry commit-certificate, its parent block did not get signed votes. for the validators that are not the current proposer, their job vote the proposed blocks. once validator receives the new block, broadcasts signed vote all validators, can collected the proposer the next epoch form the commit-certificate. two consecutive blocks and both receive commit-certificate, then the parent block and all its predecessors are considered settled. ensure safety, require that honest nodes never vote for block that conflicts with settled block. when there are forks (either due faulty proposer asynchrony), the honest nodes should vote for the blocks the longest fork. the figure below illustrates the block settlement process. assume that the proposer for height faulty, and proposed two conflicting blocks and which leads two branches. assuming neither block nor gets votes, then, neither the header nor contains the commit-certificate (denoted nil the figure). however, some point branch grows faster, and two consecutive blocks and both obtain votes. after that the upper branch block considered settled. and the lower branch can discarded. figure the block settlement process the above example also illustrates one advantage our implementation compared other pbft based protocols like tendermint block that does not receive commit-certificate can also included the settled chain, long one its successor blocks settled. for instance, block the example did not get commit-certificate, but after block settled, also considered settled. this reduces the waste computation power and helps increase the transaction throughput. analysis safety: safety means all honest validators agree the same chain blocks. more precisely, one honest validator accepts block then any future blocks accepted other honest validators will appear chain blocks that already contains the argument for safety similar casper ffg and hot-stuff and omitted here. just want point out that safety stems from the requirement that honest nodes never vote for block that conflicts with settled block. liveness: liveness means the validator committee always makes progress, i.e., always able produce and agree new blocks. here show that under our timing model, during the synchronous periods, the committee can always achieve the liveness goal. first, the "block proposal" section, have proved that the epoch can always advance, and all the honest validators march forward together. epoch where the proposer honest validator, will propose new block. for the block settlement process, liveness depends that during the synchronous periods, there are infinitely many epochs where two proposers row are honest, and wait sufficiently long form the commit-certificate. note this guaranteed happen infinitely often with the round robin rotation, since least the validators are honest. transaction throughput: with ten twenty validators, the committee can produce and settle the chain blocks rather quickly. average block production and settlement time the order seconds, and this leads high throughput much transactions per second. the block finalization process this section, will discuss the "leapfrogging" block finalization process detail. mentioned above, the guardians only need reach consensus the hashes the checkpoint blocks, which are the blocks whose heights are multiple some integer (e.g. see why sufficient finalize just the checkpoint blocks, note that the transaction execution engine the blockchain software can viewed "deterministic state machine", whereas transaction can viewed deterministic state transfer function. two nodes run the same state machine, then from identical initial state, after executing the same sequence transactions, they will reach identical end state. note that this true even when some the transactions are invalid, long those transactions can detected the state machine and skipped. for example, assume there transaction that tries spend more tokens than the balance the source account. the state machine can simply skip this transaction after performing sanity check. this way the "bad" transactions have impact the state. the context blockchain, all the honest nodes have the same copy the blockchain, they can ensured arrive the same end state after processing all the blocks order. but with one caveat the blockchain might contain huge amount data. how can two honest nodes compare whether they have the same chain blocks efficiently? here the immutability characteristic the blockchain data structure becomes highly relevant. since the header each block contains the hash the previous block, long two nodes have the same hash the checkpoint block, with overwhelming probability, they should have identical chain blocks from genesis the checkpoint. course each guardian node needs verify the integrity the blockchain. particular, the block hash embedded each block header actually the hash the previous block. note that node can perform the integrity checks its own, communication with other nodes required. interestingly, the immutability characteristic also enhances the tolerance network asynchrony even partition. with network partition, the guardians may not able reach consensus the hash checkpoint. however, after the network recovered, they can move vote the next checkpoint. they can then reach agreement, then all the blocks the next checkpoint are finalized, regardless whether not they have consensus the current checkpoint. provide byzantine fault tolerance, honest node needs assured that least two-thirds the guardians have the same checkpoint block hash. hence needs receive signatures for checkpoint hash from least two-third all guardians before the node can mark the checkpoint finalized. this ensure safety, which similar the "commit" step the celebrated pbft protocol. since the guardians only need vote checkpoint hashes every blocks, they have more time reach consensus. straightforward implementation checkpoint finalization thus follow the pbft "commit" step where each guardian broadcasts its signature all other guardians. this requires each node send, receive and process o(n) messages, where each message can couple kilobytes long. even with blocks time, this approach still cannot scale beyond couple hundred guardian nodes, unless select large value, which undesirable since increases the block finalization latency. scaling thousands guardians reduce the communication complexity and scale thousands guardians, have designed aggregated signature gossip scheme inspired the bls signature aggregation technique and the gossip protocol. the scheme requires each guardian node process much smaller number messages reach consensus, which much more practical. below are the steps the aggregated signature gossip protocol. uses the bls algorithm for signature aggregation. algorithm aggregated signature gossip finalized false, signbls(ski, heightcp hashcp), initsignervector(i) for begin send all its neighboring guardians finalized break wait for from all neighbors until timeout verify each discard invalid mod calculate the number unique signers [k] aggregate valid signatures finalized true end algorithm the aggregated signature gossip protocol the core idea rather simple. each guardian node keeps combining the partially aggregated signatures from its neighbors, and then gossips this newly aggregated signature out. this way the signature share each node can reach other nodes exponential speed using the gossip protocol. addition, the signature aggregation keeps the size the messages small, and thus reduces the communication overhead. the above diagram, the index the current guardian node. the first line the protocol uses function signbls() generate its initial aggregated signature essentially signs boneh al. survey two signature aggregation techniques message which the concatenation the height and hash the checkpoint block using the bls signature algorithm, with multiplicative cyclic group prime order and generator (pk height hashcp the first formula above, function hash function that takes both the public key pki and the message input. this prevent the rogue public-key attack. the protocol also uses function initsignervector() initialize the signer vector which dimensional integer vector whose jth entry represents how many times the jth guardian has signed the aggregated signature. after initialization, its ith entry set and the remaining entries are all set after initialization, the guardian enters loop. each iteration, the guardian first sends out its current aggregated signature and the signer vector all its neighbors. then, has not considered the checkpoint finalized, waits for the signature and signer vector from all its neighbors, waits until timeout. upon receiving all the signature and signer vectors, checks the validity using the bls aggregated signature verification algorithm. (pk height check hashcp [u] (hu pku where bilinear mapping function from gt, another multiplicative cyclic group also prime order all the invalid signatures and their associated signer vectors are discarded for the next aggregation step. worth pointing out that besides heightcp, hashcp, the above check also requires the public key pku the relevant guardians input. all this information should available locally, since when guardian locks its stake, its public key should attached the stake locking transaction which has already been written into the blockchain. hence, communication with other nodes necessary retrieve these inputs. the aggregation step aggregates the bls signature and updates the signer vector note that for the vector update, take mod for each entry. can this because (hu pku which multiplicative cyclic group prime order this guarantees that the entries vector can always represented with limited number bits. mod the algorithm then calculates the number unique signers the aggregated signature. [k] boneh al. bls multisignatures with publickey aggregation here function {true, false} maps true condition and false hence the summation counts how many unique signers have contributed the aggregated signature. the signature signed more than two-third all the guardians, the guardian considers the checkpoint finalized. the checkpoint finalized, the aggregated signature will gossipped out the next iteration. hence within o(log(n)) iterations all the honest guardians will have aggregated signature that signed more than two-third all the guardians the network not partitioned. the loop has iterations, should the order o(log(n)) allow the signature propagate through the network. analysis aggregated signature gossip correctness: prove the correctness the aggregated signature gossip protocol, need prove two claims. first, aggregated signature correctly formed honest nodes according algorithm can pass the check given formula (). second, the aggregated signature secure against forgery. stated more formally, forging fake aggregated signature the context algorithm means find and integers ... which satisfy the equation below (s, (hu pku for randomly chosen ..., pkn skn and random message hashes h..., can shown that this hard the computational diffie-hellman (cdh) problem. for the proof these two claims, please refer our multi-level bft technical report. finalization safety: safety the block finalization easy prove. under the supermajority honesty assumption, two checkpoint hashes for the same height both get aggregated signatures from least all guardians, least one honest guardian has sign different hashes for the same height, which not possible. finalization liveness: without network partition, long large enough, highly likely that after o(log(n)) iteration, all the honest nodes will see aggregated signature that combines the signatures all honest signers. this similar how the gossip protocol can robustly spread message throughout the network o(log(n)) time, even with byzantine nodes. when there network partition, consensus for checkpoint may not able reach finalization. however, after the network partition over, the guardian pool can proceed finalize the next checkpoint block. consensus can then reached, all the blocks the next checkpoint are considered finalized. hence the finalization process will progress eventually. messaging complexity: the aggregated signature gossip protocol runs for iterations, which the order o(log(n)). each iteration, the guardian needs send message all its neighboring guardians. depending the network topology, typically reasonable assume that for average node, the number neighboring nodes constant (i.e. the number neighbors does not grow the total number nodes grows). hence the number message node needs send/receive finalize checkpoint the order o(log(n)), which much better than the o(n) complexity the naive all-to-all signature broadcasting implementation. acknowledge that each message between two neighboring guardians contains dimensional signer vector where each entry integer smaller than prime however, note that this vector can represented rather compactly since most its entries are small integers practice. get more concrete idea the messaging complexity, let work out example. assume that pick -bit long prime number for the bls signature, which can provide security comparable that -bit rsa signature. and there are guardians total. under this setting, can represented with about twenty kilobytes without any compression. since most the entries are far smaller than can compressed very effectively couple kilobytes long. plus the aggregated signature, the size each message typically the kilobytes range. moreover, assume average guardian connects other guardians, then can small (more than twice log() .). this means finalizing one checkpoint just requires guardian send/receive around messages to/from its neighbors, each about couple kilobytes long. this renders the aggregated signature gossip protocol rather practical implement and can easily scale thousands guardian nodes. for further analysis, please also refer our multi-level bft technical report. reward and penalty for validators and guardians the token reward and penalty structure essential encourage nodes participate the consensus process, and not deviate from the protocol. both the validators and guardians can obtain token reward. each block includes special coinbase transaction that deposits newly minted tokens the validator and guardian addresses. all the validators can get share tokens for each block. for guardians, rewarding every guardian for each block might not practical since their number large. instead, propose the following algorithm randomly pick limited number guardians the reward recipient for each block. denote the height the newly proposed block and the most recently finalized checkpoint. the proposer should have received the aggregated signature and corresponding signer vector ccp for checkpoint cp. upon validating ccp the proposer can check the following condition for each guardian whose corresponding entry vector ccp not zero (i.e. that guardian signed the checkpoint) (pki deposit, the net return double spend always negative, and hence any rational user will have incentive double spend. the duration time-lock similar that standard payment channel. any withdrawal from the payment pool has before the time-lock expires. the blockchain returns alice the merkle proof the createpool transaction after has been committed the blockchain, well createpooltxhash, the transaction hash the createpool transaction. step initial handshake between peers: whenever alice wants retrieve the specified resource from peer (bob, carol, david, etc.). she sends the merkle proof the on-chain createpool transaction that peer. the recipient peer verifies the merkle proof ensure that the pool has sufficient deposit and collateral for the requested resource, and both parties can proceed the next steps. step off-chain micropayments: alice signs servicepayment transactions and sends them the peers off-chain exchange for parts the specified resource (e.g. piece the video file, live stream segment, etc.). the servicepayment transaction contains the following data: targetaddress, transferamount, createpooltxhash, targetsettlementsequence, sign(ska, targetaddress transferamount createpooltxhash targetsettlementsequence) the targetaddress the address the peer that alice retrieves the resource from, and the transferamount the amount token payment alice intends send. the targetsettlementsequence prevent replay attack. similar the "nonce" parameter ethereum transaction. target publishes servicepayment transaction the blockchain (see the next step), its targetsettlementsequence needs increment one. the recipient peer needs verify the off-chain transactions and the signatures. upon validation, the peer can send alice the resource specified the createpool transaction. also, note that the off-chain servicepayment transactions are sent directly between two peers. hence there scalability bottleneck for this step. step on-chain settlement: any peer (i.e. bob, carol, david, etc) that received the servicepayment transactions from alice can publish the signed transactions the blockchain anytime before the timelock expires withdraw the tokens. call the servicepayment transactions that are published the "on-chain settlement" transactions. note that the recipient peers needs pay for the gas fee for the on-chain settlement transaction. pay less transaction fees, they would have the incentive publish on-chain settlements only when necessary, which beneficial the scalability the network. note that on-chain transaction needed when alice switches from one peer another retrieve the resource. the video streaming context, this means the viewer can switch any caching node any time without making on-chain transaction that could potentially block delay the video stream delivery. shown the figure, the event that bob leaves, alice can switch carol after receiving chunks from bob, and keep receiving video segments without on-chain transaction. moreover, the total amount tokens needed create the micropayment pool (collateral deposit), which can low twice the value the requested resource, matter how many peers alice retrieves the resource from. using computational complexity language, the amount reserved token reduces from o(n) o() compared the unidirectional payment channel approach, where the number peers alice retrieves the resource from. double spending detection and penalty analysis prevent alice, the creator the micropayment pool from double spending, need able detect double spending, and ensure that the net value alice gains from double spending strictly negative. detecting double spending relatively straightforward. the validators the theta network check every on-chain transaction. remaining deposit the micropayment pool cannot cover the next consolidated payment transaction signed both alice and another peer, the validators will consider that alice has conducted double spend. next, need make alice worse off she double spends. this where the collateral comes in. earlier, mentioned that the amount collateral tokens has larger than the deposit. and here why. figure below, bob, carol, and david are honest. alice malicious. even worse, she colludes with another malicious peer edward. alice exchanges partially signed transactions with bob, carol, and david for the specified resource. since alice gains extra value for the duplicated resource, the maximum value she gets from bob, carol, and david most the deposit amount. alice colludes with edward, she can send edward the full deposit amount. she then asks edward commit the settlement transaction before anyone else and return her the deposit later. other words, alice gets the resource which worth most the deposit amount for free, before the double spending detected. later when bob, carol, david commit the settlement transaction, the double spending detected, and the full collateral amount will slashed. hence, the net return for alice netalice deposit collateral therefore, can conclude that for this scenario, long collateral deposit, alice's net return negative. hence, alice rational, she would not have any incentive double spend. can conduct similar analysis for other cases. the details are omitted here, but can shown that all cases alice's net return always negative she conducts double spend. another case that alice honest, but some her peers are malicious. after alice sends micropayment one those peers, might not return alice the resource she wants. this case, alice can turn another peer get the resource. since each incremental micropayment can infinitesimally small theory, alice's loss can made arbitrarily small. figure malicious actor detection and penalty shows malicious actor alice attempting make double spend and the resulting penalty she receives ledger storage system using public ledger facilitate the micropayments for streaming challenging, not only because high transaction throughput, but also for storage space management. achieve the "pay-per-byte" granularity, each viewer could send out payment every few seconds. with even moderate ten thousand concurrent users, could generate couple thousands transactions per second. even with the off-chain payment pool which already reduces the amount on-chain transactions dramatically, the block and state data could still balloon rather quickly. have designed storage system that addresses this problem, and can adapt different types machines, powerful server cluster running data centers, commodity desktop pc. storage microservice architecture harness the processing and storage power server clusters, the key design decision adopt the popular microservice architecture commonly seen for modern web service backends, where different modules the ledger can configured run different machines. particular, the consensus module and the storage module can separated. potentially the consensus module can run multiple machines using the mapreduce framework process transactions parallel. the theta ledger stores both the transaction blocks and the account state history, similar ethereum. the bottom layer the storage module key value store. the theta ledger implements the interfaces for multiple databases, ranging from single machine leveldb cloud based nosql database such mongodb, which can store virtually unlimited amount data. thus the ledger can run one single computer, and can also configured run server clusters. history pruning while the microservice architecture suits the powerful server clusters well, still face storage space constraints when running the ledger lower-end home pc. have designed several techniques reduce the storage consumption. similar ethereum, the theta ledger stores the entire state for each block, and the state tree root saved the header the corresponding block. reduce the space consumed the state history, the theta ledger implements state history pruning, which leverages technique called reference counting illustrated the figure below. figure state history pruning with reference counting the ledger state (i.e. the token balance each account, etc.) stored using merkle-patricia trie. figure (a) depicts the initial state tree, whose root denoted state each node the tree has attribute called the "reference count", which equal the number parents the node. the initial state tree, each node has only one parent, the reference count are all set figure (b), account updated after applying the transactions the newly settled block. hence new merkle state root state created, along with the merkle branch connecting the new root state and (the blue nodes and edges). since new nodes are added, update the reference count direct children these new nodes from some point decided delete state save some storage space. this done deleting the nodes whose reference count zero recursively starting from the root state until node can deleted. whenever node deleted, the reference count all its children will decremented one. figure (c) illustrates the process, and figure (d) shows the result the pruning. achieve the maximum level state storage compaction, once block finalized the guardian pool, can delete all the history prior that block. the ledger can also configured keep limited history states, for example, the state trees the latest blocks, depending the available storage space. can shown that with the reference counting technique, pruning state tree has the time complexity o(k log n), where the number accounts updated the transactions one block, and the total number accounts. typically, the range couple hundreds thousand. hence, pruning state tree should pretty efficient and should not take much time. managing the space consumed the transaction blocks even simpler, after block finalized, can simply delete all its previous blocks, keep limited history similar the state trees. with these techniques, common pcs and laptops are sufficient run the guardian nodes. state synchronization one the pain points using earlier generation blockchains the state synchronization time. after spinning new node, typically needs download the full block history all the way from the genesis block. this could take days complete, and already becomes hurdle for user adoption. the state and block history stored the full nodes can help reduce the synchronization time dramatically. after new node start, the first step download all the validator and guardian join/leave transactions and the headers the blocks that contain these special transaction the latest finalized block. with these special transactions and the headers which contain the validator and guardian signatures, the new node can derive the current validator committee and guardian pool. since the validator and guardian set changes are relatively infrequent, the amount data need downloaded and verified for this step should minimal. the second step, the new node downloads the state tree corresponding the latest finalized block. and needs confirm that the root hash the tree equals the state hash stored the latest finalized block. finally, the new node verifies the integrity the state tree (e.g. the validity the merkle branches). all the checks are passed, the new node can start listening new blocks and start participating the consensus process. dual currency system and token mechanics the interest securing the network, installing proper governance, and managing the usage the network, the theta blockchain will use dual currency system. the theta token will used stake, secure, and govern the theta network, while individual operations (video segment transactions, smart contract operations, etc.) will paid for with the operational token, gamma. there are two key reasons introduce second token: first, this allows the utility and purpose each token separated. theta used strictly for staking and securing the network, while gamma used power utility-based operations the network. this necessary because staking inherently decreases circulating supply, but video segment transactions and smart contracts will require highly-liquid token that can facilitate millions daily transactions. second, two tokens are needed solve possible consensus issues that arise from using the same token for staking and operations. because the token used for operations must liquid, would easier for malicious actor accumulate significant number that frequently-traded token the open market. that same token also used for staking, they could potentially threaten the security the theta network. separating the two functions (staking and operations) into different tokens, that risk greatly decreased. theta token supply and mechanics erc token, the theta token supply currently fixed billion. mainnet launch, each holder the erc theta token will receive native theta tokens the new blockchain basis. the supply native theta the new blockchain will also permanently fixed billion, meaning new theta tokens will ever created. the primary reason for fixing the theta token supply make prohibitively expensive for malicious actor acquire enough tokens threaten the network. since new theta tokens will never created, the only way acquire more purchasing existing tokens and over time making more expensive amass controlling amount theta tokens. gamma token supply and mechanics gamma the operational token the theta blockchain, used the "gas" pay for video segment microtransactions and smart contract operations. the gamma token also built the theta blockchain and ,,, gamma will generated the time mainnet launch. this initial supply gamma will distributed all theta token holders the point token swap, seeding the network with enough gamma for the network function effectively. the time the token swap, each theta token holder will also receive gamma tokens for each theta token they hold. initially, there will increase the number gamma tokens until the multi-level bft consensus mechanism launched and the guardian pool formed. after that point, validators and guardian nodes will each required stake theta tokens perform their respective functions. both validators and guardians will earn gamma proportionally according the number theta tokens they have staked, with total rewards equal target increase the supply gamma. the target increase supply gamma will initially set annually. this rate may adjusted dynamically response demand for gamma from video platforms. other words, the supply gamma will increase over the year, and you run guardian node and stake theta tokens, your share those new gamma tokens will equal your share staked theta tokens percentage the total staked theta tokens. help maintain the appropriate amount gamma circulation, all gamma used gas deploy interact with smart contracts will burned (permanently destroyed). having both gamma generation and destruction tied network usage/adoption, the number gamma tokens will maintain healthy equilibrium relative demand. validator and guardian nodes the validator set will initially made nodes operated theta labs, followed additional validator nodes operated key strategic partners. eventually, guardian nodes that perform high-standard (node availability, hardware and bandwidth requirements, etc.) and stake sufficient number theta tokens may eligible participate validator node rotating basis. our end goal for validator set comprised theta labs, video platform partners, and community members where single entity group has enough control the network act maliciously. any validator(s) were act maliciously, the guardian pool should sufficiently diversified that would act second line defense prevent malicious acts and remove malicious validators. malicious actors that take actions harm the network will also have their staked theta slashed (forfeited). expect guardian node functionality launch major upgrade following mainnet launch. standalone client will released allowing users operate guardian node and stake their theta tokens. currently constructed the protocol can support guardian nodes without sacrificing transaction throughput. achieve the optimal set guardian nodes, expect set range approximately theta tokens permitted staked per guardian node. these figures may adjusted based further testing and community feedback between now and mainnet launch. future work this whitepaper, introduced the theta protocol, new blockchain and token the incentive mechanism for decentralized video streaming network. the theta network encourages viewers share their computing and bandwidth resources and solves number technical and business challenges. there are many other technical aspects the protocol and network which classify future work, beyond the initial launch the native theta network: anti-piracy. the network can expanded include anti-piracy since tokens may used stream and cache certain content, the tokens serve "disincentive" within the network the content can tagged required tokens "premium content". general purpose service platform. the theta protocol fact independent streaming. can extended handle other types service (e.g. share computing resources) allow end users receive service for free. sidechain/plasma for "infinite transaction throughput". with the support for turing-complete smart contracts, the theta blockchain, possible build layer- constructs like sidechain, state channel, plasma top the theta blockchain achieve unlimited transaction throughput. https://www.jeffcoleman.ca/state-channels/ poon al. plasma: scalable autonomous smart contracts founding advisory team the founding members the theta network include: mitch liu mr. liu the co-founder and ceo sliver.tv, the leading esports entertainment platform with patented technology live stream top esports events fully immersive deg partnership with intel extreme masters, turner eleague, esl one and dreamhack among other global tournament operators. along with his co-founder mr. long, they currently hold two patents and two additional pending patents for virtual reality deg video streaming, and new algorithms for generating highly efficient live spherical video streams. mr. liu co-founded gameview studios best known for its tap fish mobile game franchise with nearly million downloads. the company was acquired dena, leading japanese mobile gaming company within months launch. prior that, co-founded tapjoy pioneer rewarded social and mobile video advertising, and grew that company $mm revenues. received computer science engineering from mit, completed his thesis research mit media lab "interactive cinema" video group and received mba from stanford graduate school business. jieyi long mr. long the co-founder and chief technology officer sliver.tv. leads the technical team and developed multiple patented technologies including live streaming and instant replay for video games. received b.s. degree microelectronics from peking university beijing, china. also received ph.d. degree computer engineering from northwestern university evanston, where conducted research mathematical modeling and algorithms optimize large scale electronics systems, and cryptography enthusiast. ryan nichols mr. nichols the head product and platform for sliver.tv. leads the company's esports entertainment platform built around one the largest esports virtual economies with virtual tokens circulated within two months launch. leading previous startups, he's designed and launched virtual currency systems for variety multiplayer games, including cross-game virtual currency api used hundreds third-party game developers and tens millions players worldwide. mr. nichols was director for tencent the globally popular wechat app, and co-founder live video streaming app for foodies. rizwan virk mr. virk advisor, investor and the interim head corporate development sliver.tv. mr. virk also serves the current director play labs mit, and did his research the mit media lab. mr. virk early investor cryptocurrency and blockchain companies, including ripio/bitpagos, coinmkt, bex.io, and has been active with bitangels since mr. virk the co-author several cryptocurrency related papers including online automatic auctions for bitcoin over-the-counter trading and creating peer peer system for buying and selling bitcoin online and was the designer bitcoin bazaar, one the first peer-to-peer mobile applications for in-person trading bitcoin. mr. virk received his computer science engineering from mit and his master's management from stanford graduate school business. the advisory team theta includes: